{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVS6jDEZZehW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install gradio==4.36.0\n",
        "!pip install pytube\n",
        "!pip install openai==0.28\n",
        "!pip install tiktoken\n",
        "!pip install datasets\n",
        "!pip install langchain\n",
        "!pip install sentence-transformers\n",
        "!pip install chromadb\n",
        "!pip install langchain-community\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EarhYgy4-m5_",
        "outputId": "185d0a15-eb4c-4585-db94-aa16f8799d41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.46.2\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "print(transformers.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bleBo5v7awLe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import openai\n",
        "import gradio as gr\n",
        "import pytube as pt\n",
        "import soundfile as sf\n",
        "\n",
        "from io import BytesIO\n",
        "from transformers import pipeline\n",
        "from huggingface_hub import model_info\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_bhNKW9eITd",
        "outputId": "822718aa-69d6-4ec8-9e9d-1687a9578c0a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-fd20d45149c2>:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0, openai_api_key=openai.api_key)\n"
          ]
        }
      ],
      "source": [
        "openai.api_key = \"\"\n",
        "llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0, openai_api_key=openai.api_key)\n",
        "restart_sequence = \"\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6479a716946a4944a58b9085e31153b4",
            "2a9e57afc15b4840944f6e0cec3b2904",
            "e31144cb3d8e4869975bb00580b4baea",
            "aa9488c366b64026b45ee666ebccc4d9",
            "2d45feb61dba4b969141e2ee47b6d762",
            "c5b2487f70614354873c72cb0123eabd",
            "3e5e39af3fa94c0eb862c5432a112d85",
            "7dab2df334de411eb973199f1e8d6a62",
            "8b9de9aa3d5e46b8b76e016651671ac3",
            "a415db0ce9e74f24a8a4addcbf4bc91f",
            "50084aadea974c35a466808d61355459",
            "afeae3c247244ea396c91eaccff2d402",
            "2a5fad40a67f4e27ab9fffc3c0e9bb4d",
            "f6e8b4a4f66b4dc9aacdfdaa5631c8e7",
            "558afe81275c4ee38e0521ee9ed39428",
            "12296f57ad5d454e9e2a985019af4583",
            "1c4785dcb4f24c248486b3884496b50b",
            "0f5428f0a2084ea2acf022fdc57ef78a",
            "5ca555928d5341d2a0c06743d3b37391",
            "363c89fa852c4ade8b78332f1bd64a3c",
            "8e59f625f1ac4c7ca47cd67e7f1adf39",
            "a384369da63f4e28ab2eb6b32fa841c3",
            "1d890ded050543ebae5910747b1885e2",
            "69402a209bae46369f78eaec2f02ae87",
            "07b8ec3799df4cadaaefd8c2e457bb4e",
            "23978b2505f843629193f5b3208201b6",
            "bc0df44558de4bce97102e57dc346438",
            "f5aec7bb72e443618d7e61cb1dec2cdd",
            "ec524d43464c43de889c2e2ebbcf154f",
            "5b3e1c9ff9c24fa58b76a47e76686f49",
            "f998a186ce8b4ed7b09628caaf45edb9",
            "e2ea9e6db7da43ecad0e37269c1daf76",
            "ca4b55ed4c90474aa891b1a229ef5de4",
            "2e2fc0c73d564c5ebaa21e3ac54d6452",
            "f32a9f6d153f42a882904aa97b50a866",
            "51e549d4efb1467dbe6322246fb155a0",
            "2fead089ebd841cf91fdea59a0c1a1d5",
            "e5679a00391b48f98932ef8a565a6da5",
            "9b5b39759f1a45c28b52255e678d518f",
            "a634bfea96d7443984dfed7cc200952c",
            "67b541918b654284b57c32bb92c7030b",
            "8e69055e0d084cdfaec34fc97bdc7833",
            "b2781e0ec14e4c25a63504429f83f172",
            "9664c97a403c47e7a1b5293daa730582",
            "9d2a596b1a5d42e296e11ce056f960e2",
            "49bba6c3613849568d38794ffc7edea2",
            "904d80e5c1b64bc3a372fd1df1c6ac13",
            "fedd3af175524e2485fbcb06a9224c2b",
            "ed446f1611e54ee3b6007d6706b04ede",
            "a7518f8b4120476fa11d9e777c688223",
            "a06776e9cf6343a18f183454289dc7a8",
            "614db10d85b74cbaa844922fd73dbfab",
            "7c06ba7e4cf6434897b3fa8b6e8bdca5",
            "c4346bb895514e6187015df37c02a74e",
            "689a617d2d1d4f2a8cbda22090d85a1e",
            "92586c9b824f42d392c3d26e07249d2b",
            "08f9bc963dc94e699f1fddca3eb77a68",
            "b99535777f1b4cc8b82af9c9a21e8964",
            "8923e41100804b1c9e2562853bf77d38",
            "3d6d188a13394552a7c0b977a2f0c9cb",
            "cb4824e1d393422b88cd3e01436c9799",
            "f299dfd2352f4182b719ae1604090700",
            "9096df33f5914dec8d55636f52883f29",
            "11d8b54184374928ab9169dd12411968",
            "208fa5d9fbbf46499779862bcb8106f9",
            "f863c692b42740eaa1ec6648d66750a1",
            "423da562775b4526a8fd63fb18b51b07",
            "12729c8ddbd248789b13dd87d02799e2",
            "d583d767229547208ac691870e2a7b99",
            "37ed40fc1c8a4df5b6ff9c4845d6f07e",
            "b13945729ab04381b8279be07e798f68",
            "90b0b7d2256c4861bb90c9c27ef22a83",
            "e0926d90baa7469aaa10ca7266deeaeb",
            "43755051db204c6d8b38d56ad755415d",
            "f328ad93b6214a529b9d85aa795b74dd",
            "7a4dbda5d41247dda324a687111e13bf",
            "3205dde7d1d046688dee37f24acab530",
            "7698c1dd77f340ad9e5fa393b7482c40",
            "75c7a30b4346423995d00847512b11ad",
            "34812ea9b1794099ad4468349944dab7",
            "72533e643175408ba8a0daf949874b90",
            "646d194bcdd44d40913c62f1e16fdcfb",
            "d13b5345d4944fe28de08e97681304d4",
            "301cbf71a74945ceb64e7e424ba65d42",
            "598e89c4c70144918605792ec5de6be2",
            "d4f45337c57a447198834037494bbcea",
            "bd1c56c2048743a985ca9abd733d3a02",
            "ceccba147a584bd490c85d63651bfa14",
            "51f99d9922af40c0aef398b2c526a39d",
            "83c52ad8cb114dffacc9e7aeef678c9f",
            "a7ad545929b64a61b3a16aafd15ad4fd",
            "8efebc61ac294372b78efaf3f9733d34",
            "d98f6bc25f064527873b2671a3c3ccac",
            "97b955a338294ff1a970f44345d612ea",
            "3875601645be4c319400dbdb15fd7f29",
            "ba9f3b83f19845308af58511d2cde134",
            "f7bd4c6a048a4aa9885dbf8eb953635e",
            "6a5585a2405e43e19e6ea763c008701f",
            "fed14a894e0b4f85be39a827096ab2ad",
            "d7db3576e9ce4cdcbe7f0564608b29e6",
            "763df8ec3a7d4b27936dc64073ddb289",
            "848d1e9323764d2c84d3959230c5522c",
            "b1226fe24fcb411084ee4be9f1fef846",
            "0b9c3a2313684f9e93146a0735d5f397",
            "bd114a8ee1054e74ab339954ebaa7377",
            "b6bc7154bf294a14bb2f8e4a9cdff15c",
            "6eec048a676e404f9e4521bf144fe8c2",
            "487cb669a93f42fc9bfc37d00e6f02e0",
            "2c38bbe228504a4084cc78e465d3be17",
            "afea07abb3ef4b648d78088573ce8a27",
            "1b22b3369f034d2bb6078d02cc267edf",
            "7af866cfca3147b0b9a13d8f3bbb76f6",
            "9323fe629c82429da4112d5baaf34aaf",
            "c9783b0f881c43a6b1c62d4c049ace0a",
            "06b51d7cd54848f8b7619b5f61a583c7",
            "72eaf70bd75f44948d372440be247612",
            "acd3c17e5ff04a479a4f11b4a3dcb0ff",
            "8a057ae0484447d39091132eadeb59cf",
            "facabaacf3684954a829f8f9e23ace2b",
            "23f0962b90334e8690611a2faa388c18",
            "ff5ed62f8e9e4b84bb88a8065e124816",
            "2b2d8214546c443ab07ffe94597d10bf",
            "b8659d9f35d84ab3bd60295db757c3c0",
            "b2a614b5129d49e3abc25b55cac8cc6a",
            "59066b4e11e94bebb64b25d41fa7fe84",
            "ec2c1c310234473b90bf0b5bb8f5fc9a",
            "b8b5797fc99640c0a398500c42b3feea",
            "7b59a615892343499af2e6c103a9cbe7",
            "891c4e7bb85e43b4899920a94fee6695",
            "d6fb218515fd459b9a8d045c569bc5bb",
            "78e65b72ac804f31878ba70f26fcec75",
            "4f21ac425116445792062e36749d50fe",
            "c5c7310e4371434b9b01144fca857462",
            "83244e1f66574786aa02643a000d29b3",
            "19c619321d714992b98b2f13716cb95e",
            "584cde44a3114a0c8c1d0968e59bdc1a",
            "ca5a328fcb26413bae79fddb3b980cb2",
            "e45f271933e445cd86b130a510e7837c",
            "ceb0fde16a91408f83c96b2c6ecafe45",
            "4ccdbf10ea7a4f8389a2d3e48a87aea3",
            "b7df5067df2642e3adc158565f66106c",
            "54f81ae24e2f4fc595768cfda7dcba09",
            "436d44ad1dc94d0585744ab23d1d5054",
            "1bc43e5a822c4d878db086ea7d9d8ea2",
            "64d434cf136442e48c5bd9c1a53004ae",
            "d4df867c01d74eabb1cfee247eca27f2",
            "f24ca440a7e945bbafc109d43acaa4f4",
            "0c2ba9ad08c7453088fe9d77f807b901",
            "9d223887c2604559a532eee1fd21775b",
            "03844803a433498094f9b19f7ae94f8c",
            "d3b806202283411fbec38e63d45867cb",
            "ff27e9bc8ff54139a67944ee00dbdf22",
            "9b08dc98047144b49cba4e497f737474",
            "5b4ffac5a46a4695b816d63adb69bb7a",
            "7977e8e8bfd545ce9729d1109748d18f",
            "2906410f6b39490eaabcad9838467d07",
            "f45a9e9b7b52410bacc42c9881c31001",
            "962d145dff154fb38c3d1b09b6d943a3",
            "f405e16ccb9e472eba22a526aaf7e8b5",
            "06a2b17fde8f49d7ae54e9f6ce236ff6",
            "067b46ed368a4877a0dd707c9db580e6",
            "699ef10470e044928139461d8ff0d146",
            "112616e5c64540c0bdf9a2c8400797f9",
            "457ab038d1aa446f88e9ea4474d358b1",
            "05a105b4895f4ab59e37daa9da274bdd",
            "32f9cd2177b84ddd8ad7692fe6ac7070",
            "5c0f71540f08469ea85a838e22779dfd",
            "e893fa556a70471ab0c44190dc7cd4e9",
            "9477f098f48e40c0a143748fff888cf6",
            "fa722ebde0124255bcd5748d0936ad45",
            "b4c433d61cb640e89f55ba243e5be86e",
            "f5a5593771554fff99a0fa37aa5cf70f",
            "2df70eac76844d8590236e7ab5ceaabf",
            "65dd61b615c44a21b12e5e78c700d97e",
            "8e2124d564324c96b0a47b30b2d16e74",
            "c74778b18a3f4857846b82fbea7e1086",
            "8287e6e697284b2d8f8bb54a88aafc99",
            "a56165fe7adc4fa686c38b999a8bb4d3",
            "705a11adce464f51a5b9c2f4f20fd6a2",
            "cfd96a2196a94a7eabdfb1b7df0abc30",
            "a636935eadee4df182b2d15406f2b18a",
            "72a0697a6e6b49a6b5cc577a139306df",
            "06a394d57cac484fa0782759d068d96c",
            "f62416530a3140f988afd9903b650a45",
            "f0a1b6938cc34bc1a0e5eb0a2f57ff66",
            "f991668cff1848399600fca0a1917152",
            "608b659e2280431abaee0aefd2c680f8",
            "4f19074e74a246c18dd08fd828b416b4",
            "d86b113874f64ef198399c3ad32a1ebc",
            "d40c391537e841a58b98dc9b2482c76e",
            "a4a654d50f9b4f688dbf79ed8999ee50",
            "926d0fa777da4c2780b263532678ba3d",
            "394a659489c641dbbebb4d62e538f700",
            "003eef1822634bdda2f3716a058ed5b1",
            "848d343f06c54eddaba5509109858364",
            "da733446c571415491f8f553aa5166dd",
            "8485556571e040fb8c38aa53e3870c79",
            "3494e16305274abf9b4a14032f692c59",
            "d2895a674aa64f08b8b93eb643decb45",
            "ebd26a11258843e8aec1b87a8faa0c55",
            "83d35269d8494966be333d87178716fc",
            "4e620a53abdd42548dcb0024aaca5a76",
            "3f49b9b8ffa04a76b50778ebe0c288e1",
            "9772cb4e678f41c79ce3cf6c04cbad9b",
            "da012e09be2c4dbfb207825d8aa7d51c",
            "88eb6b1165814e5793be5008f1634888",
            "eaf926a596384c84a5b44005a6aa0efb",
            "49ad569445dc47a789b316242f9fe856",
            "49a0eb33d0194cadb1eb67f161e7c4db",
            "6060e4ddb7f84bdf87f50f040c7f59bf",
            "def7356435bd4a829786b96f2f0c4059",
            "bbb0b7384e1847abbab4b7278cd73564",
            "076142e63dce4501be61c8cc3b55386c",
            "240dd93c82324a96aa925a0a631a1bb6",
            "a6cd53a5ca3744f088a25fc3a695f263",
            "076fbfb47fb34b7e83980a92c42295d6",
            "8a3fcd1107ed44ff953b5d92e4ea0ede",
            "f9d5ddf5c5ef40b18a61f9d475531e47",
            "749e3a76bab5495587693002c72883de",
            "97ecd9e39ee24691a017cb165298ffec",
            "b6826e49494d4f6f80b343ea3685ef20",
            "0e7bbdc7e4dc45a3bcfc57e574c2c510",
            "d229dea460214dfb933c0c3d272b74f6",
            "8f0a26d388b54c5c91024cf629227c38",
            "4d3834a66f9841c6a25addc06f13f809",
            "ed240314a2ce49dc80d0f00bfab72ae9",
            "0cd3339f069c45688a5f645bed40a572",
            "891aa345ab974f9c9c1ff28da8a8db5d",
            "de726e976e744b018f2a3270342055b3",
            "469a3e7ef21f4a1bbcf581645621c85b",
            "fa25729590944edb9bf46febf0b0caf6",
            "523f5f55b28448acb3a7a8c5f2f5877e",
            "50209c2eeca04449a56ba2b690653222",
            "54ada2de69c04449be03c5aa5da4ce27",
            "583a5d1083c548a4b94e486f93992df4",
            "0c2f3faee84a47b3985410802622ea46",
            "f72e79fbefd14a399263090baef37f83",
            "7108c61053374a01b1c691a698782a79",
            "ec8344282e334e779ebd671925acfccc",
            "db73c8aadec340faa88f8066f97a7830",
            "cb6b2496b9224942a65fb1a632d3b5ef",
            "1e2c3cc4dd2d4577b88cf02158bf9275",
            "30050a8c6c29466b806843b507905d03",
            "2719b3c705e540f18da349f91819b16a",
            "10d07b1fdf6745d9a517c390538d7337",
            "ed34e40ceba242a6be60ea559f665e26",
            "bc01e036bd1c46e193eabba30bfeb655",
            "2f33b33199e541f79667a66505f0a949",
            "dc1bc083f02d49e390f787704c42a435",
            "533ff9839b3041d5b94d6e25b4e968b1",
            "a1e77f0c34e84dafa2deed3f2cefb30c",
            "3f5beb68f9ad47c8aa76c301f2a27b1e",
            "9cf1eebe9cf543d790dd0f6e554d3bd9",
            "e892df6fe3264dc79af6328eb90ccce1",
            "0542c468eade4846b4d574de37484822",
            "a1de77e81e934f5a8fa4595523252137",
            "da600e558f694844a4dec932d3ecad79",
            "580d1f7f8c45407d9566ed04c1f3b66a",
            "7693e22906924cd89372850430d93988",
            "117a6871ca914078986bcb591e2df93b",
            "83c0d958a43f4ed5aa666ab10638c377",
            "0fceb88683d644fabcb6cec7a016744d",
            "48f39098326a49b0bead8eee1393b905",
            "bc2b4a01be204a0d9566f0f111b6afba",
            "3a7f0bd6fe5a409c92d1c60d4aa67659",
            "a96f69bbef674c29bf2fab7629276233",
            "19daa547191b4bf6a9c1e61d7b1426fc",
            "e9e81c820cca419a94e3245e7bf93289",
            "feffdfa968f14884bb81f98e4ec218d3",
            "fdb3218595a24007ab8d90af010dcb95",
            "c2344403c2a24b738529466cba2d8f12",
            "f513e5d5d6de497389a21cf9f3305db8",
            "e8436eb00e0544c28de6eed9babbdac0",
            "24e9099d38ed4bc88f1f3e6e9a7fce6f",
            "f45d7b427fd84bfc84f829e26a4077f9",
            "53adde0999f24ef490ce5e0945d5a3b2",
            "2406ed56f3ae44c1b1aa36d058860360",
            "7d016edc8e1c475d9c13f87c164751f8",
            "449f580d80cc41b2a44c992a055af57f",
            "d10e97f89b8d4a9883caeee9961c5191",
            "98127c31d10745bdb31a269464a3d994",
            "eb267c3f7dc04014bc15824e53ef16cb",
            "f92f2bf661a84cd3ac04e01f1db5927b",
            "6b6aa2d5e6604735b20ddcb05697d119",
            "4d161c97ec724b11b695da6ac6b8be64",
            "b7e46bd46a204596a67dce44b91701fe",
            "c619aab8e7b341f7b320ccf37d1c9c4e",
            "3e46832e6ac1472d8f37782e5108be4d",
            "419a6bf64e7f400dbc9013d9a63aaee8",
            "c1b7ed53c0664a34b5e0a21f48ec80fa",
            "9acfc2d20f4c4980a3a76ef77b3f5f3a",
            "163f5ea06656463ab4a992be7a67bdc2",
            "c43997393223445ebdc4ce94dbdd38b5",
            "e009aa4b446348d4b8f1c8f033fabdbd",
            "d32b7c88e87649888a48b7f6c4aae735",
            "f25f3c4f40304f8eb822eedabfbc5aad",
            "a7a0c0bb05814735afa74744d5237127",
            "efb29f1da9694375a5e96153729c28ac",
            "15d58f4a8de4445692d1bddca2d814da",
            "520572538727489fabe65865f3216e48",
            "614cdfd3547144f09f819dc6e413b09b",
            "69d7fb3aa8f64e3fa551d6a7fdd97c77",
            "d04201799ee446fb873f2ea9fb1fd633",
            "4423f0de3e0e4fdfbe3f97f99c687cfb",
            "92d206e3bb19493abbf865bc4a4ca288",
            "3798406ad5104736b9d21626eb5bcef9",
            "8051f2ff115148f78f90eba611552783",
            "5c4cdd49bf384f158c83c333a0c0decd"
          ]
        },
        "id": "lAWPAgarOWgc",
        "outputId": "c5d662f4-c752-43a9-8002-f6ca45b5c674"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-23344a49eb43>:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/LaBSE')\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6479a716946a4944a58b9085e31153b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afeae3c247244ea396c91eaccff2d402",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d890ded050543ebae5910747b1885e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/2.22k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e2fc0c73d564c5ebaa21e3ac54d6452",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d2a596b1a5d42e296e11ce056f960e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/804 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92586c9b824f42d392c3d26e07249d2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "423da562775b4526a8fd63fb18b51b07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/397 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7698c1dd77f340ad9e5fa393b7482c40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/5.22M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51f99d9922af40c0aef398b2c526a39d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.62M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7db3576e9ce4cdcbe7f0564608b29e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b22b3369f034d2bb6078d02cc267edf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b2d8214546c443ab07ffe94597d10bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "2_Dense/config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5c7310e4371434b9b01144fca857462",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bc43e5a822c4d878db086ea7d9d8ea2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7977e8e8bfd545ce9729d1109748d18f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.64k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32f9cd2177b84ddd8ad7692fe6ac7070",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/145M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8287e6e697284b2d8f8bb54a88aafc99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f19074e74a246c18dd08fd828b416b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/488 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2895a674aa64f08b8b93eb643decb45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/47.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6060e4ddb7f84bdf87f50f040c7f59bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6826e49494d4f6f80b343ea3685ef20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/967M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "523f5f55b28448acb3a7a8c5f2f5877e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30050a8c6c29466b806843b507905d03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e892df6fe3264dc79af6328eb90ccce1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a7f0bd6fe5a409c92d1c60d4aa67659",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53adde0999f24ef490ce5e0945d5a3b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/2.11k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c619aab8e7b341f7b320ccf37d1c9c4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efb29f1da9694375a5e96153729c28ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0, openai_api_key=openai.api_key)\n",
        "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/LaBSE')\n",
        "synthesiser = pipeline(\"text-to-speech\", model='facebook/mms-tts-yor')\n",
        "\n",
        "MODEL_NAME = \"omoekan/whisper-small-yoruba\" #this always needs to stay in line 8 :D sorry for the hackiness\n",
        "lang = \"yo\"\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "pipe = pipeline(\n",
        "    task=\"automatic-speech-recognition\",\n",
        "    model=MODEL_NAME,\n",
        "    chunk_length_s=30,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "pipe.model.config.forced_decoder_ids = pipe.tokenizer.get_decoder_prompt_ids(language=lang, task=\"transcribe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVDQVTdGP26J",
        "outputId": "2c37ec36-4227-4363-8dc2-4c6ad9e6fb52"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-dc5418bc0279>:12: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  embedding = OpenAIEmbeddings(openai_api_key=openai.api_key)\n"
          ]
        }
      ],
      "source": [
        "loader = TextLoader('/content/filtered_yoruba.txt', encoding = \"utf-8\")\n",
        "documents = loader.load()\n",
        "\n",
        "persist_directory = '/content/chroma/'\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50,separators = \".\")\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "#db = Chroma.from_documents(docs, embeddings)\n",
        "#retriever = db.as_retriever()\n",
        "\n",
        "embedding = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
        "db = Chroma.from_documents(docs, embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfGLh1SSNbp2",
        "outputId": "7bfcd98c-a479-4ce8-d905-f05130a2d091"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfcEB9ZKU9o5",
        "outputId": "bd14bab6-67a2-46a2-b742-04777ad40cf3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "méjìlá\n"
          ]
        }
      ],
      "source": [
        "# Build prompt\n",
        "# Define prompt\n",
        "question = \"Ipinlẹ melo wo ni Yakubu Gowon kọkọ da ni ọdun 1967 ?\"\n",
        "template = \"\"\" Use the following pieces of context to answer the question at the end in yoruba. If you don't know the answer, just say rara o, don't try to make up an answer.Keep the answer as concise as possible. Please don't make anything up, just reply with\n",
        "rara o if you are not at least 90% sure of your answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
        "\n",
        "#Define the llm to use\n",
        "llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0, openai_api_key=openai.api_key)\n",
        "# Run chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=db.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")\n",
        "\n",
        "result = qa_chain({\"query\": question})\n",
        "final_result = result['result']\n",
        "\n",
        "print(final_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT6cEYEQjDhV",
        "outputId": "6359bfaf-1e2f-4dbe-dcd0-69d1bede0e02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/filtered_yoruba.txt'}, page_content='.86\\xa0\\']\\n\\nQuestion: Ọwọ orilẹ-ede wo ni Sierra Leone ti gba ominiria?\\nAnswer: [\\'Ilẹ̀ Gẹ̀ẹ́sì\\']\\n\\nQuestion: Iwe melo ni Thomas Carlyle ti kọ?\\nAnswer: [\\'Oogun\\']\\n\\nQuestion: Ọdun wo ni a sọ Femi Falana di amofin agba?\\nAnswer: [\\'Ọdun 2012\\']\\n\\nQuestion: Ki lorukọ ọba ookanlelogun ilu Warri ?\\nAnswer: [\\'Ogiame Atuwatse III\\']\\n\\nQuestion: Iku wo lo pa Adolph Hitler ?\\nAnswer: [\\'suicide\\']\\n\\nQuestion: Ẹgbẹ oṣelu wo ni o se iṣakoso Ikọle ekiti ni ọdun 2019 ?\\nAnswer: [\\'APC\\']\\n\\nQuestion: Elo ni barẹli epo ti wọn reti pe ilẹ-ise ifọ epo Dangote yoo ma seto lojumọ?\\nAnswer: [\\'650,000\\']\\n\\nQuestion: Ta ni onitọhun ti o sọ Naijiria ni orukọ ti o n jẹ ?\\nAnswer: [\\'Flora Louise Shaw\\']\\n\\nQuestion: Ọjo melo ni Fisayo Soyombo lo ninu ewon Ikọyi nigbati o n se se iwadi?\\nAnswer: [\\'ọjọ́ márùn-ún\\']\\n\\nQuestion: ọdun wo ni Chinyere Yvonne Okoro bẹrẹ isẹ oṣere?\\nAnswer: [\\'2002\\']\\n\\nQuestion: Ni ọdun wo ni a bi Bassey Henshaw?\\nAnswer: [\\'Ọdun 1943\\']\\n\\nQuestion: Tani Alakoso Agba orile-ede Kanada lowo lowo?\\nAnswer: [\\'Justin Trudeau\\']\\n\\nQuestion: Ta ni oludari fiimu \"Lionheart\" ti o jade lọdun 2018 ?\\nAnswer: [\\'Genevieve Nnaji\\']\\n\\nQuestion: Ilu meloo lo wa ni orilẹ ede Fransi\\nAnswer: [\\'mejidilogun\\']\\n\\nQuestion: Kini orukọ owo ti wọn n naa ni orilẹ-ede China?\\nAnswer: [\\'yuan\\']\\n\\nQuestion: ṣe eniyan alawo funfun nikan laleri ni orile ede Amerika?\\nAnswer: [\\'no\\']\\n\\nQuestion: Nigba wo lọ da egbe agbabọọlu Real Madrid silẹ?\\nAnswer: [\\'6 Èrèlé 1902\\']\\n\\nQuestion: Ara ẹgbẹ akọrin westlife wo loku ni ọdun 2009 ?\\nAnswer: [\\'Gately ku ni ile rẹ ni Port d\\'Andratx, Mallorca, ni kutukutu ọjọ 10 Oṣu Kẹwa Ọdun 2009')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result['source_documents'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "L7-PdwfbgZTP",
        "outputId": "20053f23-1872-4553-9e33-cd2091b76eab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mẹ́tàdínlógójì'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_answer(\"Awọn ipinlẹ melo lo wa ni Naijiria?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DPddZXbZmxV"
      },
      "outputs": [],
      "source": [
        "def transcribe(microphone, file_upload):\n",
        "    warn_output = \"\"\n",
        "    if (microphone is not None) and (file_upload is not None):\n",
        "        warn_output = (\n",
        "            \"WARNING: You've uploaded an audio file and used the microphone. \"\n",
        "            \"The recorded file from the microphone will be used and the uploaded audio will be discarded.\\n\"\n",
        "        )\n",
        "\n",
        "    elif (microphone is None) and (file_upload is None):\n",
        "        return \"ERROR: You have to either use the microphone or upload an audio file\"\n",
        "\n",
        "    file = microphone if microphone is not None else file_upload\n",
        "\n",
        "    text = pipe(file)[\"text\"]\n",
        "\n",
        "    return warn_output + text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8oCdUC4clfe"
      },
      "outputs": [],
      "source": [
        "def get_prompt(microphone, file_upload):\n",
        "  question = transcribe(microphone, file_upload)\n",
        "  prompt = \"\"\" Use the following pieces of context to answer the question at the end in yoruba. If you don't know the answer, just say rara o, don't try to make up an answer.Keep the answer as concise as possible. Please don't make anything up, just reply with\n",
        "  rara o if you are not at least 90% sure of your answer.\n",
        "  {context}\n",
        "  Question: {question}\n",
        "  Helpful Answer:\"\"\"\n",
        "  return question, prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz1V-kjYvuZX"
      },
      "outputs": [],
      "source": [
        "# Build prompt\n",
        "def get_answer(microphone, file_upload):\n",
        "  question, template = get_prompt(microphone, file_upload)\n",
        "  # Define prompt\n",
        "  QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
        "\n",
        "  #Define the llm to use\n",
        "  llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0, openai_api_key=openai.api_key)\n",
        "  # Run chain\n",
        "  qa_chain = RetrievalQA.from_chain_type(\n",
        "      llm,\n",
        "      retriever=db.as_retriever(),\n",
        "      return_source_documents=False,\n",
        "      chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        "  )\n",
        "\n",
        "  result = qa_chain({\"query\": question})\n",
        "  final_result = result['result']\n",
        "\n",
        "  return final_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrEgPeOs3mpJ"
      },
      "outputs": [],
      "source": [
        "from transformers import VitsModel, AutoTokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def synthesis(microphone, file_upload):\n",
        "  question = transcribe(microphone, file_upload)\n",
        "  text = get_answer(microphone, file_upload)\n",
        "  tts_output = synthesiser(text)\n",
        "  audio_data = tts_output[\"audio\"][0]\n",
        "\n",
        "  with BytesIO() as buffer:\n",
        "      sf.write(buffer, audio_data, 16000, format='wav')\n",
        "      audio_bytes = buffer.getvalue()\n",
        "\n",
        "  return question, text, audio_bytes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "LrvCBBJM0_v_",
        "outputId": "7d0b616c-406e-4cc1-f101-3ef6fc2ea348"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:983: UserWarning: Cannot load light. Caught Exception: module 'huggingface_hub.utils' has no attribute '_errors'\n",
            "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IMPORTANT: You are using gradio version 4.36.0, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://20f56305ad8ad63810.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://20f56305ad8ad63810.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://20f56305ad8ad63810.gradio.live\n"
          ]
        }
      ],
      "source": [
        "def synthesis(text):\n",
        "  text = text\n",
        "  tts_output = synthesiser(text)\n",
        "  audio_data = tts_output[\"audio\"][0]\n",
        "\n",
        "  with BytesIO() as buffer:\n",
        "      sf.write(buffer, audio_data, 16000, format='wav')\n",
        "      audio_bytes = buffer.getvalue()\n",
        "\n",
        "  return audio_bytes\n",
        "\n",
        "\n",
        "css = \"\"\"\n",
        "body {\n",
        "    background-color: white !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=synthesis,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Input text\"),\n",
        "    ],\n",
        "    outputs= [gr.Audio(label=\"Generated Speech\")],\n",
        "    title=\"YorubaAI\",\n",
        "    description=(\n",
        "        \"Chat with YourbaAI and get answer to your questions in Yoruba\"\n",
        "    ),\n",
        "    allow_flagging=\"never\",\n",
        "    theme=\"light\",\n",
        "    css=css,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uMzVs1N8YJpY",
        "outputId": "f2206e1f-b7f4-4348-8582-386f46529cac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:983: UserWarning: Cannot load huggingface. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/huggingface (Request ID: Root=1-66d95f4a-6fce835768a8240f103910f8;24bf9318-556b-420b-92c1-6639cbf86a10)\n",
            "\n",
            "Sorry, we can't find the page you are looking for.\n",
            "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://bfda19f73754be9095.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://bfda19f73754be9095.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1375: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 532, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 276, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1923, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1509, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 832, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-12-cdcb06e47390>\", line 7, in synthesis\n",
            "    question = transcribe(microphone, file_upload)\n",
            "  File \"<ipython-input-9-dd9869cb1130>\", line 14, in transcribe\n",
            "    text = pipe(file)[\"text\"]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/automatic_speech_recognition.py\", line 284, in __call__\n",
            "    return super().__call__(inputs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 1249, in __call__\n",
            "    return next(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
            "    item = next(self.iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\", line 269, in __next__\n",
            "    processed = self.infer(next(self.iterator), **self.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 1164, in forward\n",
            "    model_outputs = self._forward(model_inputs, **forward_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/automatic_speech_recognition.py\", line 504, in _forward\n",
            "    tokens = self.model.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py\", line 637, in generate\n",
            "    decoder_input_ids, kwargs = self._prepare_decoder_input_ids(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py\", line 1649, in _prepare_decoder_input_ids\n",
            "    prev_start_of_text = suppress_tokens[-2] if suppress_tokens is not None else None\n",
            "IndexError: index -2 is out of bounds for dimension 0 with size 0\n"
          ]
        }
      ],
      "source": [
        "demo = gr.Interface(\n",
        "    fn=synthesis,\n",
        "    inputs=[\n",
        "        gr.Audio(sources=\"microphone\", type=\"filepath\"),\n",
        "        gr.Audio(sources=\"upload\", type=\"filepath\"),\n",
        "    ],\n",
        "    outputs= [gr.Textbox(label=\"Question asked\"), gr.Textbox(label=\"Generated text\"), gr.Audio(label=\"Generated Speech\")],\n",
        "    title=\"YorubaAI\",\n",
        "    theme=\"huggingface\",\n",
        "    description=(\n",
        "        \"Chat with YourbaAI and get answer to your questions in Yoruba\"\n",
        "    ),\n",
        "    allow_flagging=\"never\",\n",
        ")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "81e684a77cad47ef9a87550909c05548",
            "cd806f02da614d1b8a9601fcca861e15",
            "5268bc97f246480d98ef871ef291faa8",
            "5eb173904a254e1b8337d4b4313caac3",
            "d7b491fc627e433e93256d47b145de2a",
            "9893b9b77e7340d7b438657d5c192405",
            "dd1c56569b8549219510a8e1373b6228",
            "f52b5d7fcd27486d88fc9eeb303adb06",
            "481aafa2c67f4140b8a8cf514744ab10",
            "1616a91766c14e309293817ff4a5f38a",
            "eefbfa771efd4e83957f1db269ae4633",
            "fa06092dc7ab48409c3d85617a610fb6",
            "3009fd772a1444ad8a85d717a2b320a6",
            "4745f72bc8d9457589430ec797cbc418",
            "683528c8fca244e28de06155b59e8116",
            "09fe5b4c5b224392b209a2301a4f46c6",
            "1fb00f99d2f643b9a22f5add8ace0a92",
            "b074d662f3ef4424b60ed07e913f377c",
            "ffc4a70ad01441839d88c49150cb2ce3",
            "27decdd82c484da5ae2af27a437214c9",
            "63b50ef0e55349dea4fa5d45edd0d20c",
            "0d7d811b99034bd7b7a211df9d49eb07",
            "178f2fe1d83b45538e3447027cd4d196",
            "6b6433d8bb8d4eefa88658175c798b8c",
            "e7ab73340c334a14a5168f872973bdb3",
            "aace368cb117497187a5931f11ada402",
            "38edf312936b4591b47d9a6add1f8da3",
            "0c683d3844ea4f949fa0dbb432cffd4c",
            "0ffd7e61e8f847059d2b5a610b160f56",
            "f68a568cd5ff49c78f8142de09056d18",
            "16da162ca7244a45a622060007685c9e",
            "3915473ae34e411b8f209f95579f9b73",
            "8e95eaeaf28b4df4a2a8f97942228370",
            "a101d0df32584b5b80d861326006b818",
            "ea73ef4a9d4544b6a2cbe334567679b6",
            "a14daa6dd3914d5388c59e67a7aeec5f",
            "5bdefa1f788a49a4a2dc131d05c4340e",
            "8ea2f6e85ab24007a3455e47f1f30adf",
            "653bb65bd2104d4285dd05fe44cc60f9",
            "346b617712454539b24a3960a8e0ae23",
            "3a26cfb805ae4cabb7fdf1aa4fc4a21f",
            "cc17520ff4604963944336380d39c54f",
            "d5492a9dbc0b4aa781f29300d128fecb",
            "0f86762cfcc241f79fa326cfa7cf0b96",
            "a3ffe3a4da114f55a926ced7782adf0c",
            "3aed126c96df4fc1935148eaa8be35ba",
            "f98b41748865470f9856172267dfa222",
            "7e061361862a44208ed93ea807ca294e",
            "7f61a3be815741a7b9321607efb8e430",
            "481ea15fa9984791a43369c50f30fef5",
            "3b6f0bdbeae74cb09c62f9a8ffce482a",
            "9e573cb0db5045f6b65b24f015a53621",
            "bb41d5fd69cf4325a19f8928a2af542d",
            "6a126f5befbd44f58fab9a3e207fea08",
            "682727a3b6df466aaf85ef0a2d4975f7",
            "1d9f5f2a9aef434f8ee29ad409391b5c",
            "836da6125f534087b99c11e0b4519357",
            "f34886b87a694f1fbf8cb0519b5b81db",
            "4374727ea4e44925a9350bf90186c206",
            "c2d3fdc42c7d49ac93d6ed56d13680b2",
            "8c457ea04fb7437d9e5c47aa70d7fc45",
            "9dc7b205d9c645bd86ccd0c0c1c37474",
            "ba128a23657540a7b9ccc02ef1e47ad7",
            "11ed946fb667467abd11ba844fc65b1e",
            "45ca8a5d5acf47c0b758b78a4d0195e9",
            "315171e3f8624797b5ddb07963433a7b"
          ]
        },
        "id": "dwpk7tp6bKYP",
        "outputId": "22d457f8-c7f8-496e-cd5b-56ea0277a27e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81e684a77cad47ef9a87550909c05548",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/38.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa06092dc7ab48409c3d85617a610fb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/37.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "178f2fe1d83b45538e3447027cd4d196",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/37.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a101d0df32584b5b80d861326006b818",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/360 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3ffe3a4da114f55a926ced7782adf0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/361 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d9f5f2a9aef434f8ee29ad409391b5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/332 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "ds = load_dataset(\"masakhane/afriqa\", \"yor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnBivxzbz3hu",
        "outputId": "9eb54741-1441-4c80-929d-e6218f1f1e17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['question', 'answers', 'lang', 'split', 'translated_question', 'translated_answer', 'translation_type'],\n",
              "        num_rows: 360\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['question', 'answers', 'lang', 'split', 'translated_question', 'translated_answer', 'translation_type'],\n",
              "        num_rows: 361\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['question', 'answers', 'lang', 'split', 'translated_question', 'translated_answer', 'translation_type'],\n",
              "        num_rows: 332\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPfd8VWeKocc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ds = pd.read_excel(\"/content/drive/MyDrive/Otherweb/yoruba.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uVRcGj1rdz5"
      },
      "outputs": [],
      "source": [
        "# Writing text to a file\n",
        "with open('yoruba.txt', 'w') as file:\n",
        "  for i in range(330):\n",
        "    file.write(f\"Question: {ds['train']['question'][i]}\\n\")\n",
        "    file.write(f\"Answer: {ds['train']['answers'][i]}\\n\")\n",
        "    file.write(\"\\n\")\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    file.write(f\"Question: {ds['test']['question'][i]}\\n\")\n",
        "    file.write(f\"Answer: {ds['test']['answers'][i]}\\n\")\n",
        "    file.write(\"\\n\")\n",
        "\n",
        "    file.write(f\"Question: {ds['validation']['question'][i]}\\n\")\n",
        "    file.write(f\"Answer: {ds['validation']['answers'][i]}\\n\")\n",
        "    file.write(\"\\n\")\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdjK3fB6tU7t"
      },
      "outputs": [],
      "source": [
        "ds.set_format(\"pandas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_flSDexu97i1"
      },
      "outputs": [],
      "source": [
        "data = ds[\"train\"][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xPgeUhFX-Biq",
        "outputId": "23cc1f9d-4735-4d97-e16c-5468a56ce26b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 33819,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33819,\n        \"samples\": [\n          \"73496\",\n          \"40064\",\n          \"46637\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33819,\n        \"samples\": [\n          \"https://yo.wikipedia.org/wiki/Olukorede%20Yishau\",\n          \"https://yo.wikipedia.org/wiki/3667%20Anne-Marie\",\n          \"https://yo.wikipedia.org/wiki/14327%20Lemke\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33819,\n        \"samples\": [\n          \"Olukorede Yishau\",\n          \"3667 Anne-Marie\",\n          \"14327 Lemke\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15180,\n        \"samples\": [\n          \"Tuwon shinkafa j\\u1eb9 \\u1ecd\\u0300kan l\\u00e1ra \\u00e0w\\u1ecdn ounj\\u1eb9 Naijiria ati Niger t\\u00ed \\u00f3 w\\u00e1 lati Niger ati apa ariwa oril\\u1eb9 \\u00e8d\\u00e8 Naijiria .    O j\\u1eb9 o\\u00fanj\\u1eb9 t\\u00ed w\\u00f3n \\u0144 fi iresi \\u1e63e, t\\u00ed w\\u00f3n s\\u00ec \\u0144 fi \\u1ecdb\\u1eb9\\u0300 miyar kuka, miyar kubewa, ati miyar taushe j\\u1eb9  Ona m\\u00e9j\\u00ec ni w\\u1ecd\\u0301n fi \\u0144 se o\\u00fanj\\u1eb9 y\\u00ec\\u00ed, w\\u00f3n le fi \\u00c0gb\\u00e0do se(\\u00e8y\\u00ed t\\u00ed w\\u1ecd\\u0301n p\\u00e8 n\\u00ed tuwon masara), w\\u1ecd\\u0301n s\\u00ec le fi \\u00ecy\\u00e8fun oka s\\u1eb9\\u0301(\\u00e8y\\u00ed t\\u00ed w\\u1ecdn \\u0144 p\\u00e8 n\\u00ed tuwon dawa).\",\n          \"K\\u00f3st\\u00e1 Rik\\u00e0 (), lonibise o je Orile-ede Olominira ile Kosta Rika( tabi , ) je orile-ede ni Arin Amerika, o ni bode mo Nicaragua ni Ariwa, Panama ni ilaorun ati guusu, mo Okun Pasifik ni iwoorun ati guusu ati mo Omi-okun Karibeani ni ilaorun. \\n\\nKosta Rika, to tumosi \\\"Eti Odo Olora\\\", ti pa constitutionally ise ologun re re pelu ilana-ibagbepo ni 1949.  Ohun nikan ni orile-ede Amerika Latini to wa ni akojo awon orile-ede 22 oseluarailu pipejulo. Kosta Rika lemolemo ti wa larin awon orile-ede Amerika Latini to gaju nipa Atoka Idagbasoke Eniyan, o si wa ni ipo 54th lagbaye ni odun 2007. O wa ni ipo keta lagbaye, ati akoko ni gbogbo Amerika, nipa Atoka Bi Ayika Se Wa ni 2010.\\n\\nNi 2007 ijoba Kosta Rikan sekede eto fun Kosta Rika lati di orile-ede ti ko lo karbon ni 2021. Gege bi New Economics Foundation se so, Kosta Rika gba ipo kinni ninu Atoka Planeti Adunnu beesi ni o je orile-ede \\\"alawoewe julo\\\" lagbaye.\\n\\nItan \\n\\nKi Columbus o to wa ibe ri awon omo abinibi ile Kosta Rika je apa were part of the Agbegbe Arin kariaye to budo si awon agbegbe idasa Mesoamerika ati Andes. Eyi ti je siodotun lati kopo ipa agbegbe Isthmo-Colombian. Ibi yi ni awon asa abinibi Mesoamerika ati Guusu Amerika ti pade.\\n\\nApa ariwaiwoorun orile-ede yi, Peninsula Nikoya, ni o je ibi guusujulo fun ipa asa Nahuatl nigbati awon olubori ara Spein de be ni orunddun kerindinlogun. Arin ati apaguusu orile-ede ni ipa Chibcha. Sibesibe, awon eniyan atilewa ti kopa lori asa Costa Rican odeoni niye to kere, nitoripe opolopo ninu won ku lowo awon arun bi smallpox ati idamu latowo awon alamusin ara spein.\\n\\nItokasi\",\n          \"Margret Elizabeth Rey (ti a bi Margarete Elisabeth Waldstein ; Osu ke\\u00e9r\\u00ecnd\\u00ednl\\u00f3g\\u00fan, odun 1906 di O\\u1e63u kejila \\u1ecdj\\u1ecd K\\u1ecd\\u0300kan l\\u00e9 n\\u00ed og\\u00fan, \\u1ecddun 1996) j\\u1eb9 onk\\u1ecdwe ati alaworan ara ilu Am\\u1eb9rika kan ti o j\\u1eb9 \\u1ecdm\\u1ecd Jamani, ti a m\\u1ecd dara jul\\u1ecd fun jara Curious George ti aw\\u1ecdn iwe aworan aw\\u1ecdn \\u1ecdm\\u1ecdde ti oun ati \\u1ecdk\\u1ecd r\\u1eb9 H.A. Rey \\u1e63\\u1eb9da lati 1939 di 1966.\\n\\nIgbesi aye \\nMargarete Elisabeth Waldstein ni a bi ni O\\u1e63u Karun \\u1ecdj\\u1ecd 16, \\u1eccdun 1906 ni Hamburg, Ottoman Jamani, \\u1ecdm\\u1ecdbinrin Gertrude (Rosenfeld) ati Felix Waldstein .    Baba r\\u1eb9 j\\u1eb9 \\u1ecdm\\u1ecd \\u1eb9gb\\u1eb9 ti Reichstag . O k\\u1ecd \\u1eb9k\\u1ecd ayaworan ni Bauhaus ni Dessau, Kunstakademie D\\u00fcsseldorf, ati University of Munich laarin 1926 ati 1928 ati l\\u1eb9hinna \\u1e63i\\u1e63\\u1eb9 ni ipolongo.  Ni 1935 o l\\u1ecd kuro ni Germany fun Rio de Janeiro, ni Brazil lati sa fun Nazism ( Nazi Germany ) - ati lati pade Hans Reyersbach, oni\\u1e63owo kan ati Juu German miiran lati Hamburg, ti o j\\u1eb9 \\u1ecdr\\u1eb9 \\u1eb9bi kan.  W\\u1ecdn \\u1e63e igbeyawo ni \\u1ecddun 1935 ati gbe l\\u1ecd si Paris, France, ni \\u1ecddun 1936. \\n\\nLakoko ti o wa ni Ilu Paris, aw\\u1ecdn aworan \\u1eb9ranko Hans wa si akiyesi akede Faranse kan, \\u1eb9niti o fi a\\u1e63\\u1eb9 fun u lati k\\u1ecd iwe aw\\u1ecdn \\u1ecdm\\u1ecdde. Abajade, Cecily G. ati aw\\u1ecdn obo m\\u1eb9san, j\\u1eb9 iranti di\\u1eb9 loni, \\u1e63ugb\\u1ecdn \\u1ecdkan ninu aw\\u1ecdn ohun kik\\u1ecd r\\u1eb9, \\u1ecdb\\u1ecd to dara kan ti a np\\u00e8 ni Curious George, j\\u1eb9 iru a\\u1e63ey\\u1ecdri b\\u1eb9 ti t\\u1ecdk\\u1ecdtaya naa \\u1e63e akiyesi kik\\u1ecd iwe kan nipa r\\u1eb9. W\\u1ecd\\u0301n d\\u00e1 i\\u1e63\\u1eb9\\u0301 w\\u1ecdn d\\u00far\\u00f3 n\\u00edgb\\u00e0 t\\u00ed Ogun \\u00c0gb\\u00e1y\\u00e9 Kej\\u00ec b\\u1eb9\\u0300r\\u1eb9\\u0300 s\\u00ed \\u00ed j\\u00e0. G\\u1eb9g\\u1eb9bi aw\\u1ecdn Ju, aw\\u1ecdn Reys pinnu lati sal\\u1ecd kuro ni Paris \\u1e63aaju ki aw\\u1ecdn Nazis gba ilu naa. Hans k\\u1ecd\\u0301 k\\u1eb9\\u0300k\\u1eb9\\u0301 m\\u00e9j\\u00ec, w\\u1ecd\\u0301n s\\u00ec s\\u00e1 k\\u00far\\u00f2 n\\u00ed Paris n\\u00ed w\\u00e1k\\u00e0t\\u00ed m\\u00e9l\\u00f2\\u00f3 kan \\u1e63\\u00e1\\u00e1j\\u00fa k\\u00ed \\u00f3 t\\u00f3 \\u1e63ub\\u00fa. Lara aw\\u1ecdn ohun-ini kekere ti w\\u1ecdn mu p\\u1eb9lu w\\u1ecdn ni iwe af\\u1ecdw\\u1ecdk\\u1ecd alaworan ti Curious George .\\n\\nThe Reys' odyssey mu w\\u1ecdn w\\u00e1 si aala France ati Spain  lati w\\u1ecd Spain, ibi ti nw\\u1ecdn ti ra reluwe tiketi si Lisbon, ni Portugal . L\\u00e1ti ib\\u1eb9\\u0300, w\\u1ecd\\u0301n pad\\u00e0 s\\u00ed Brazil, n\\u00edbi t\\u00ed w\\u1ecd\\u0301n ti p\\u00e0d\\u00e9 n\\u00ed \\u1ecdd\\u00fan m\\u00e1r\\u00f9n-\\u00fan s\\u1eb9\\u0301y\\u00ecn, \\u1e63\\u00f9gb\\u1ecd\\u0301n n\\u00ed \\u00e0k\\u00f3k\\u00f2 y\\u00ec\\u00ed w\\u1ecd\\u0301n \\u0144 b\\u00e1 a l\\u1ecd s\\u00ed \\u00ccl\\u00fa New York n\\u00ed United States . Aw\\u1ecdn iwe naa ni a t\\u1eb9jade nipas\\u1eb9 Houghton Miffin ni \\u1ecddun 1941, botil\\u1eb9j\\u1eb9pe aw\\u1ecdn iyipada kan ni lati \\u1e63afihan nitori im\\u1ecd-\\u1eb9r\\u1ecd ti akoko naa. Hans ati Margret ni ak\\u1ecdk\\u1ecd gbero lati lo aw\\u1ecdn aw\\u1ecd omi lati \\u1e63e apejuwe aw\\u1ecdn iwe naa, \\u1e63ugb\\u1ecdn niw\\u1ecdn bi w\\u1ecdn ti ni iduro fun ipinya aw\\u1ecd, o yi iw\\u1ecdnyi pada si aw\\u1ecdn aworan aworan efe ti o t\\u1eb9siwaju lati \\u1e63afihan ninu \\u1ecdk\\u1ecd\\u1ecdkan aw\\u1ecdn iwe naa. Atil\\u1eb9jade alakojo p\\u1eb9lu aw\\u1ecdn atil\\u1eb9ba Onya olomi (watercolors) ti tu sil\\u1eb9 ni \\u1ecddun 1998. \\n\\nCurious George j\\u1eb9 a\\u1e63ey\\u1ecdri lojukanna, ati pe aw\\u1ecdn Reys ni a fun ni a\\u1e63\\u1eb9 lati k\\u1ecd aw\\u1ecdn i\\u1e63\\u1eb9l\\u1eb9 di\\u1eb9 sii ti \\u1ecdb\\u1ecd aburu ati \\u1ecdr\\u1eb9 r\\u1eb9, \\u1ecckunrin ti o ni Fila Yellow. W\\u1ecdn k\\u1ecd aw\\u1ecdn itan meje ni gbogbo r\\u1eb9, p\\u1eb9lu Hans ni ak\\u1ecdk\\u1ecd \\u1e63e aw\\u1ecdn apejuwe ati Margret ti n \\u1e63i\\u1e63\\u1eb9 pup\\u1ecd jul\\u1ecd lori aw\\u1ecdn itan, botil\\u1eb9j\\u1eb9pe aw\\u1ecdn mejeeji gbaw\\u1ecd lati pin i\\u1e63\\u1eb9 naa ati ifowosowopo ni kikun ni gbogbo ipele idagbasoke. Ni ak\\u1ecdk\\u1ecd, sib\\u1eb9sib\\u1eb9, oruk\\u1ecd Margret ni a fi sil\\u1eb9 kuro ni ideri, o \\u1e63ee \\u1e63e nitori pe aw\\u1ecdn obinrin kan wa t\\u1eb9l\\u1eb9 ti nk\\u1ecd aw\\u1ecdn itan-ak\\u1ecd\\u1ecdl\\u1eb9 \\u1ecdm\\u1ecdde. Ni aw\\u1ecdn at\\u1eb9jade nigbamii, eyi ni atun\\u1e63e, ati pe Margret ni bayi gba kir\\u1eb9diti kikun fun ipa r\\u1eb9 ni idagbasoke aw\\u1ecdn itan naa.\\n\\nMargret ati \\u1ecdk\\u1ecd r\\u1eb9 ko l\\u1ecd si Cambridge, Massachusetts, ni 1963, ni ile kan ti o sunm\\u1ecd Harvard Square . L\\u1eb9hin iku \\u1ecdk\\u1ecd r\\u1eb9 ni \\u1ecddun 1977, Margret t\\u1eb9siwaju iwe kik\\u1ecd, ati ni 1979 o di \\u1eccj\\u1ecdgb\\u1ecdn \\u1e62i\\u1e63\\u1eb9da Ik\\u1ecdweni Ile-\\u1eb9k\\u1ecd giga Brandeis ni Waltham, Massachusetts . Lati \\u1ecddun 1980 o \\u1e63e ifowosowopo p\\u1eb9lu Alan Shalleck lori l\\u1eb9s\\u1eb9s\\u1eb9 aw\\u1ecdn fiimu kukuru ti o \\u1e63afihan Curious George ati lori di\\u1eb9 sii ju mejila mejila aw\\u1ecdn iwe afikun.\\n\\nNi \\u1ecddun 1989 Margret Rey \\u1e63e agbekal\\u1eb9 Curious George Foundation lati \\u1e63e iranl\\u1ecdw\\u1ecd fun aw\\u1ecdn \\u1ecdm\\u1ecdde ti o \\u1e63\\u1eb9da ati \\u1e63e idiw\\u1ecd iwa ika si aw\\u1ecdn \\u1eb9ranko. Ni 1996, o \\u1e63e aw\\u1ecdn \\u1eb9bun pataki si Ile-ikawe gbangba ti Boston ati Ile-i\\u1e63\\u1eb9 I\\u1e63oogun Deaconess Beth Israel . O tun j\\u1eb9 alatil\\u1eb9yin igba pip\\u1eb9 ti Longy School of Music .\\n\\nRey ku nipa ik\\u1ecdlu \\u1ecdkan ni O\\u1e63u kejila \\u1ecdj\\u1ecd 21, \\u1ecddun 1996 ni Cambridge, Massachusetts.\\n\\nAw\\u1ecdn iwe ti a gba \\nGbigba Litireso Aw\\u1ecdn \\u1ecdm\\u1ecdde de Grummond ni Hattiesburg, Mississippi, ni di\\u1eb9 sii ju aw\\u1ecdn apoti \\u1ecd\\u0301\\u1ecd\\u0300d\\u00fanr\\u00fan ti aw\\u1ecdn iwe Rey ti o wa ni 1973 si 2002. \\n\\nD\\u00f3k\\u00edt\\u00e0 Lena Y. de Grummond, \\u1ecd\\u0300j\\u1ecd\\u0300gb\\u1ecd\\u0301n n\\u00ed \\u1eb9\\u0300ka \\u00ecm\\u1ecd\\u0300 s\\u00e1y\\u1eb9\\u0301\\u01f9s\\u00ec \\u00eck\\u00e0w\\u00e9 n\\u00ed The University of Southern Mississippi, k\\u00e0n s\\u00ed Reys n\\u00ed \\u1ecdd\\u00fan 1966 n\\u00edpa \\u00e0k\\u00f3j\\u1ecdp\\u1ecd\\u0300 \\u00ecw\\u00e9 \\u1ecdm\\u1ecdd\\u00e9 tuntun ti USM. H.\\u00a0A. ati Margret \\u1e63et\\u1ecdr\\u1eb9 aw\\u1ecdn aworan af\\u1ecdw\\u1ecdya meji ni akoko y\\u1eb9n. Nigbati Margret Rey ku ni \\u1ecddun 1996, yoo \\u1e63e ipinnu pe gbogbo ohun-ini iwe-kik\\u1ecd ti Reys yoo j\\u1eb9 it\\u1ecdr\\u1eb9 si Grummond Collection.\\n\\nIta \\u00ecj\\u00e1p\\u1ecd \\n\\n Margret Rey at IMDb\\n Dinitia Smith, \\\"How Curious George Escaped the Nazis\\\", The New York Times, September 13, 2005\\n Margret and H. A. Rey Interactive Timeline: Life in Paris and a Narrow Escape\\n Guide to the H. A. Rey Papers 1940\\u20131961 (University of Oregon) at Northwest Digital Archives \\u2014 with historical note\\n Curious George Saves the Day: The Art of Margret and H. A. Rey, The Jewish Museum of New York, March 14, 2010 \\u2013 August 1, 2010\\n Margret Rey at Library of Congress Authorities, with 152 catalog records\\n See IMDB: Monkey Business: The Adventures of Curious George's Creators (2017)\\n[[\\u1eb8\\u0300ka:\\u00c0w\\u1ecdn \\u1ecdj\\u1ecd\\u0301al\\u00e1\\u00ecs\\u00ed n\\u00ed 1996]]\\n[[\\u1eb8\\u0300ka:\\u00c0w\\u1ecdn \\u1ecdj\\u1ecd\\u0301\\u00ecb\\u00ed n\\u00ed 1906]]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ca23a149-3e66-47b3-9693-52462c6b193c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>598</td>\n",
              "      <td>https://yo.wikipedia.org/wiki/A</td>\n",
              "      <td>A</td>\n",
              "      <td>el: άλφα\\n yo: a (ah)\\n\\naa ab ac ad ae af ag ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>599</td>\n",
              "      <td>https://yo.wikipedia.org/wiki/B</td>\n",
              "      <td>B</td>\n",
              "      <td>B\\n\\n el: βήτα\\n\\nba bb bc bd be bf bg bh bi b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>600</td>\n",
              "      <td>https://yo.wikipedia.org/wiki/C</td>\n",
              "      <td>C</td>\n",
              "      <td>C\\n\\nca cb cc cd ce cf cg ch ci cj ck cl cm cn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>601</td>\n",
              "      <td>https://yo.wikipedia.org/wiki/D</td>\n",
              "      <td>D</td>\n",
              "      <td>D\\n\\n ar: ?\\n el: δέλτα (Δ δ)\\n he: ?\\n hi: ?\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>602</td>\n",
              "      <td>https://yo.wikipedia.org/wiki/E</td>\n",
              "      <td>E</td>\n",
              "      <td>E\\n\\n ar: ?\\n Cyrillic: ?\\n el: έψιλον (Ε ε)\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca23a149-3e66-47b3-9693-52462c6b193c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca23a149-3e66-47b3-9693-52462c6b193c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca23a149-3e66-47b3-9693-52462c6b193c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-012652ac-c7a6-47c0-aede-e309a04d0da2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-012652ac-c7a6-47c0-aede-e309a04d0da2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-012652ac-c7a6-47c0-aede-e309a04d0da2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    id                              url title  \\\n",
              "0  598  https://yo.wikipedia.org/wiki/A     A   \n",
              "1  599  https://yo.wikipedia.org/wiki/B     B   \n",
              "2  600  https://yo.wikipedia.org/wiki/C     C   \n",
              "3  601  https://yo.wikipedia.org/wiki/D     D   \n",
              "4  602  https://yo.wikipedia.org/wiki/E     E   \n",
              "\n",
              "                                                text  \n",
              "0  el: άλφα\\n yo: a (ah)\\n\\naa ab ac ad ae af ag ...  \n",
              "1  B\\n\\n el: βήτα\\n\\nba bb bc bd be bf bg bh bi b...  \n",
              "2  C\\n\\nca cb cc cd ce cf cg ch ci cj ck cl cm cn...  \n",
              "3  D\\n\\n ar: ?\\n el: δέλτα (Δ δ)\\n he: ?\\n hi: ?\\...  \n",
              "4  E\\n\\n ar: ?\\n Cyrillic: ?\\n el: έψιλον (Ε ε)\\n...  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yWs9jh2-SgQ"
      },
      "outputs": [],
      "source": [
        "data.to_csv(\"/content/drive/MyDrive/Otherweb/yoruba.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zESwCHW5-hFE",
        "outputId": "64dfddb5-d443-491f-f751-43fe27685923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Ki ni iṣẹ ti Chief Bọde Thomas n ṣe ki o to kuro laye ?\n",
            "Answer: ['alakoso ile ijọsin Afirika ti Naijiria']\n",
            "\n",
            "Question: Awọn ipinlẹ melo lo wa ni Naijiria?\n",
            "Answer: mẹ́rìndínlógójì\n",
            "\n",
            "Question: Ipinlẹ melo wo ni Yakubu Gowon kọkọ da ni ọdun 1967 ?\n",
            "Answer: méjìlá\n",
            "\n",
            "Question: Ijọba ibilẹ meloo lo wa ni orilẹ ede Naijiria?\n",
            "Answer: ẹ̀rin-dín-ní-ojì dín ní ẹgbẹ́rin\n",
            "\n",
            "Question: Ta ni o tumọ bibeli si ede Yoruba ?\n",
            "Answer: ['Samuel Ajayi Crowther']\n",
            "\n",
            "Question: Ni ọdun wo ni a da ile-ẹkọ Rufus Giwa Polytechnic silẹ?\n",
            "Answer: ['Ọdun 1979']\n",
            "\n",
            "Question: Ọdun wo s'ọdun wo ni Olúṣẹ́gun Ọ̀ṣọbà jẹ  Gómìnà Ìpínlẹ̀ Ògùn n'ilẹ Naijiria?\n",
            "Answer: ['oṣu kini ọdun 1992 titi di oṣu kọkanla ọdun 1993']\n"
          ]
        }
      ],
      "source": [
        "# prompt: read the test file yoruba.txt\n",
        "\n",
        "with open('/content/filtered_yoruba.txt', 'r') as file:\n",
        "  content = file.read()\n",
        "print(content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHalgh322dcN"
      },
      "outputs": [],
      "source": [
        "def remove_empty_answers_from_text_file(file_path):\n",
        "    # Read data from the text file\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Initialize variables\n",
        "    filtered_data = []\n",
        "    question = None\n",
        "    answer = None\n",
        "\n",
        "    # Process each line\n",
        "    for line in lines:\n",
        "        if line.startswith(\"Question:\"):\n",
        "            question = line.strip()\n",
        "        elif line.startswith(\"Answer:\"):\n",
        "            answer = line.strip()\n",
        "            # Check if the answer is empty (e.g., 'Answer: []')\n",
        "            if answer != \"Answer: []\":\n",
        "                filtered_data.append((question, answer))\n",
        "\n",
        "    # Write the filtered data back to a new file\n",
        "    with open('filtered_yoruba.txt', 'w', encoding='utf-8') as file:\n",
        "        for q, a in filtered_data:\n",
        "            file.write(f\"{q}\\n{a}\\n\\n\")\n",
        "\n",
        "# Usage example\n",
        "file_path = '/content/yoruba.txt'  # Replace with your file path\n",
        "remove_empty_answers_from_text_file(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970,
          "referenced_widgets": [
            "6302a20fda7447e6a4ef3f3a7be152aa",
            "b0ad6f97a09d4d9aa03412c5908a92a6",
            "6987e9a0f7e649bebb3eaee822be458d",
            "49c6dfb07eca441baa9f46f761b51caa",
            "470132bcf9d9485aa5a693f8713c0436",
            "0f58485967314f05bd9f0a90896d2086",
            "7ca419a9b8104ed680f168193b61fa97",
            "1f5d751882ac44a4a4b1a8b392054b15",
            "e8e5b681845248548bd27ea76aca7aea",
            "b1147f0da4e34244bbfaf72571e90a62",
            "82126dc695d24673a48965aac4a4bee8",
            "bff179b92d95479595b24268cf28abb1",
            "e864e0a7b1a748ef868564803e940c46",
            "8d6e72aba65d41e08ff878edc3ce1b5f",
            "5a4cccc75cf548a6993b156a2a95f789",
            "27f517d8035343d5a7a93c5ef52ee368",
            "e30d0f19b5434d8382929c3951f21f7c",
            "4a70b6ea30c3460797cdd949fa937823",
            "60a39db9ebc345fd98cea04121aeda6c",
            "25b141bdf1a547afb9bd752e82a64875",
            "a77dec93fa074b038ddeebb36e34e3d8",
            "f91ac5ad06964f9bbe048c6bcd8764d2",
            "e9b97420d0ed4200af978884a5cff1f4",
            "4648a48e0eb844a08656b8e30b414838",
            "a109c8c56ad44a4ea2fd62ed9cb67717",
            "f0458bccb04847968bef4a8a4f987032",
            "1d868483bef04a6799822da22e19f52f",
            "2e9cc93ee1cf4e9a959ba7773f9f1251",
            "c14e07653ba7407db146c907da1d7587",
            "8493597750eb40e3a0cf378111565d4e",
            "5bddb39bf46c428cb933f0596c972395",
            "4384d59ae4b14c7e8b61a81d1990c465",
            "2aef8232160f46dea1d439bd60e24f0e",
            "5d30130281164abb8f283e2afdb2277d",
            "b5234acc64934399a72e5f9dadbdb585",
            "539949baa1514f83ac0227ccf58535a7",
            "0e0e539679bf4e3fb3113d1d8383343c",
            "f025fa9a02714515bb96aed65044bd80",
            "24ae724a72bc4a60b7a007814b31bc89",
            "54f84a6bc2ce4858bb6592913b500f7b",
            "d60aa71d085145f4b691a0c1fb255c68",
            "10092127641e458daa4dc44319ebcdd8",
            "0f36dcf64b9c408ba6a742179646cbac",
            "459298c779f946d3ae8393b354a13387",
            "75a98cd8072d43f88ab1cd1ecf82c5c4",
            "0c6a1d896ae246dbae767099eb39cc97",
            "933f57db8f8144caba221772df143526",
            "3ebc7fb66f524943a7fc43fcf3282a0d",
            "fdd140d0ebba414ba45fafd6e7b1ff62",
            "9bacea42197d459ebd33b66173ee110d",
            "684cbdcc8072492ba5cb81807ae6e89d",
            "eba080269fed44f99a4e5853a4d3ba2a",
            "0d37749848a14dca9f33ac6bac370f4b",
            "4851a06a054b4708900019067f6127c2",
            "90692b981e604dc883b9672f41cfd08a",
            "b43c6f873d0a4ac2bcbca370f6f8c9e0",
            "4b11e5d7a5d04b21b675fbb76527ffbc",
            "aa06e55005504ab4b8a9154245f12c5c",
            "b83d6489f6704d36aa2480d71360b4bb",
            "55713c130f834d9d9c4551d022debf3c",
            "bdf0d8aafbf64204b1ea48c9d3e04334",
            "0149af55af9c4f0b848ac5c5fff10f8a",
            "62a49fb227bb4327bdcfe289e2c830e4",
            "21bc2495aff44d94bad710097b762211",
            "1562ba234e4d46d78e1b9fd2dbf98eaf",
            "46465522f6c54e65abf832f1b89d39ab",
            "8062f7a26a4f4fbdbe9541cb77c39349",
            "36e523a2afc344d4bc598838afdf08dd",
            "16c9a8382e334aa0a7e0ec763e029107",
            "0a6fe184133f4af88e1c0cd0fc880b78",
            "78e66733ee154e61ae5bbd45ed157272",
            "01a99c27e277475ab908a1ba4d47b2f1",
            "1053569de318465b81bc9ef40a1a3685",
            "da2f25204cee44e9ad7282f45cd24015",
            "83d1f18e8d7844ebb31d470ffb4eda46",
            "72869556bef14c94b00ee1a901492473",
            "89f03ab4d4ee4427a60c7755e46dfebe",
            "b60d4212b47e49a1a5862b0711187def",
            "47a0dfddc9104b3195f8147c394fe6df",
            "3f902ea296fd4d5999d170c4c5aa584a",
            "cd4646abc3df4146abc70dc1bf4fe6ea",
            "921e513340bb4e938e81c669500eb36a",
            "c100948f42184fb399c35c2a282cfc19",
            "e3d40c5e50bd4d08b70e3a55f161641e",
            "1b4e66c737ec49c9afe3c5c0ec34e927",
            "16f069c1687e48fab7fc3cbb4c1dd62f",
            "bc21d5dc1e7b4f55843d3c53dc67bcfe",
            "fec504570cb14b7a8fbab3842eaa3268"
          ]
        },
        "id": "gJYoIJez1aWq",
        "outputId": "0c0f5283-e048-4a9b-cc86-7c453ef63e69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6302a20fda7447e6a4ef3f3a7be152aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bff179b92d95479595b24268cf28abb1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vulavulaslm.py:   0%|          | 0.00/42.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/lelapa/InkubaLM-0.4B:\n",
            "- vulavulaslm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9b97420d0ed4200af978884a5cff1f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.66G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d30130281164abb8f283e2afdb2277d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:778: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75a98cd8072d43f88ab1cd1ecf82c5c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/960 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b43c6f873d0a4ac2bcbca370f6f8c9e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/991k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8062f7a26a4f4fbdbe9541cb77c39349",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/3.95M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b60d4212b47e49a1a5862b0711187def",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "VulavulaLlamaForCausalLM(\n",
              "  (model): VulavulaLlamaModel(\n",
              "    (embed_tokens): Embedding(61788, 2048)\n",
              "    (layers): ModuleList(\n",
              "      (0-7): 8 x VulavulaLlamaDecoderLayer(\n",
              "        (self_attn): VulavulaLlamaAttention(\n",
              "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (rotary_emb): VulavulaLlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): VulavulaLlamaMLP(\n",
              "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
              "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
              "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): VulavulaLlamaRMSNorm()\n",
              "        (post_attention_layernorm): VulavulaLlamaRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): VulavulaLlamaRMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=61788, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"lelapa/InkubaLM-0.4B\", trust_remote_code=True, use_auth_token=\"\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"lelapa/InkubaLM-0.4B\", trust_remote_code=True, use_auth_token=\"\")\n",
        "\n",
        "model.to('cuda')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBrYviMGGn-7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
