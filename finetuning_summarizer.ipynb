{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install sentencepiece\n",
        "!pip install datasets\n",
        "!pip install py7zr\n",
        "!pip install torch\n",
        "!pip install sacrebleu\n",
        "!pip install rouge_score\n",
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "-MbYhVONq7wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "3dp6eieJOWf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset_samsum = load_dataset('csv', data_files= '/content/news_headlines_1.csv',split='validation') #engine='python', quoting=csv.QUOTE_NONE)\n",
        "data_files = {\"train\": \"/content/drive/MyDrive/Otherweb/seo_short_headline/seo_headline_train.csv\",\n",
        "              \"valid\": \"/content/drive/MyDrive/Otherweb/seo_short_headline/seo_headline_valid.csv\",\n",
        "              \"test\": \"/content/drive/MyDrive/Otherweb/seo_short_headline/seo_headline_test.csv\"}\n",
        "dataset_samsum = load_dataset('csv', data_files=data_files)\n",
        "dataset_samsum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356,
          "referenced_widgets": [
            "31dbb50fd13848d1865b11e0463f0c37",
            "d813479f87aa4f428cd1c6c4a549fb97",
            "5a96676aa39543d188ca5fcbac15062a",
            "1981b405931a49f9abbe8f662f87592a",
            "a82d8b93296e42e1a00e932a343c3358",
            "a5d5393ae95d4e48b086ad166867edc7",
            "9f9f469b5ef541cc9700c163088277a2",
            "13930fbe4fdd44b6a0c24968c19a546c",
            "6477bca7e4994f23817da2f25126a09e",
            "1be4d6823b3b4c6eb32d96df4d4a0f76",
            "3904e258d5e54d118620512cba500400",
            "db7e3f5835f3498a97ef62471e13aa96",
            "9bd5788e4400400b928273a72a80bf67",
            "2b865f15abe342d2907d1de2f20b9678",
            "188f525b169f45b49ecaab530741ac55",
            "a4605a7ec11b49b2b907baa2193920b9",
            "5b5a1313bd7b4f4ea6481e888d1e8905",
            "8e6241982a11465bbd5ac9280bec9181",
            "a00e480e276a44a9acf7989715892aec",
            "a034a4534ba948f39d025cbd6a4b03fc",
            "cd72f503837d49ffb86417377ff2f168",
            "ab2509a8a833489da0608115a4e05ce4",
            "43fc7d033e4547ee910efce6e101ff6a",
            "af14c38f44814cd181fc99c0fa697c55",
            "f93d98a0d8f2477680a10bb370a91106",
            "02f170891d5f4156abeb898a25ccdcf7",
            "40749bae0ef64cc5a927755e54b26f23",
            "37d63f8bbe7046b0ad4c92276e1c6fd8",
            "a033b1adb95b46a29f1d1858be24a0db",
            "db038a60e645427cb2480f937b32a88f",
            "2ad6b7ffd5c64156806bc0422d145d4d",
            "3b44e0d4de0146a99d1ef465092b552d",
            "c36cd93f37d64776a2f47ac12b0a037b"
          ]
        },
        "id": "_l2MKJbUHmGL",
        "outputId": "13caef28-0793-4041-f47e-7ca15c3ca5ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31dbb50fd13848d1865b11e0463f0c37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating valid split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db7e3f5835f3498a97ef62471e13aa96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43fc7d033e4547ee910efce6e101ff6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Excerpt', 'Summary'],\n",
              "        num_rows: 49673\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['Excerpt', 'Summary'],\n",
              "        num_rows: 975\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['Excerpt', 'Summary'],\n",
              "        num_rows: 96\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_csv('/content/news_headlines_1.csv') #engine='python', quoting=csv.QUOTE_NONE, header=None,delimiter=\",\")"
      ],
      "metadata": {
        "id": "EpCBipOhVIjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "model_name = 'google/pegasus-cnn_dailymail'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348,
          "referenced_widgets": [
            "d9a8d5b43f68419e9c6991c65b79a906",
            "0a94d2c744e346a586b7f28434657d2d",
            "9148cca7161f469ca6af6dff8b629266",
            "e83c0b97affc41d2b2ed67b9cef45bb9",
            "6cc23f99f56f44f2bef0e972fd8a9a2b",
            "7416b04659174345a2be6df4bc37a23c",
            "f595d0c1e2364c5a96adcadfa34b5a7d",
            "aae04c704fdf4290879bcc27de8b391f",
            "6ea57263a90e4b17b05a3773be70df27",
            "c05e3ee5d115487d8ce14889a25fa298",
            "8b27ad5390b5479a91120784a0dd586f",
            "0b078990051e49f2bff0c0b5f7b57e25",
            "0e5d8000c0ee4e479d4fa00af2921ef3",
            "bb0c3c2c1a734da5850e300ba3058e4b",
            "0065bc4e8ece456ca3f2f5c340ff7084",
            "00392d6bdc9c43829905482994da7667",
            "039e1c974cbd45158ea8799aeaef7b52",
            "56b260aaa03444a38ce7c91066a76df5",
            "7386857de8fb44228a5acec17859c9c4",
            "5c88c537f0f24ce9ac7969cc103c0631",
            "fff61b8415864f67922a4f31834fe183",
            "5cda57407b8a46cbb117153d6045f318",
            "cfde8136b3a44dc89ecaec241867f130",
            "82daee9711b848bd85198134c3fd6472",
            "d0bfdf2933d942e19dd84d92bd69ce14",
            "7c60d2dff71a4890952950db3539cfb7",
            "2e8d5f187f97486cab9092b2b41441c7",
            "fa910771708348d8bb4f495feaab3087",
            "8d4ac9e270a544f2a117231c0ebdd22b",
            "732fd02c88254b7ab56be8a4ac523bed",
            "c561f0f884554466ab07c9982ee158e6",
            "123ab00ca56c4137af6fa731ce5cad62",
            "c3dc2f2cf1184bfd86dcbed8d2b952f0",
            "ab0b0715063f42ec8d1b6cf167a9d71d",
            "7cfaef67715143b1be13355b4fd34686",
            "f525189867a2475a93057d7177b1aba3",
            "dae8003694b7400e95e0e759dc12d10d",
            "bed216b21d9044ba93b570ae826e0aed",
            "5f8ff26980c74900871557a59aa3c426",
            "e06c381805d14b7690d2e98785ce98ed",
            "800b0914f2bc4e32aa5da800d6e68cc5",
            "c02391a454e64dbb9968e461b3f9afed",
            "c106f4b666694f588042af84986f1233",
            "e4a40bb0cfbf483fa6afc7d942b00e02",
            "beb43319ab05419fb6adffeeb3ce9094",
            "92100ba259f744209d0fe3fec767c8d9",
            "ddae3fb7fb2f4c2197d206f4e7da7e4f",
            "85dc95638bcd45178323c9bdd8abcaf2",
            "96cfef12c6d040c28ffa7c788bccbb6d",
            "1e4bfd4a3aea4feeb941aae19c84f344",
            "e86f6c36f33644fb89aea63cbd83f499",
            "41e18a1960514539b6662c46f152a02f",
            "fff88d9e868140b19549d086d594ac25",
            "afee3ea9826b41269f745fdb4f59c307",
            "342c0e8f299a42f5872240b568735b7c",
            "40048b208fa44c2a8538527cd03cf28f",
            "7fed85ddfaa944ed956458cf2dbfd348",
            "3e042b1ead2a4fe2bc537ef45603e445",
            "b07c075f53414cec94e5aacf4bdf7a1c",
            "52eeb20875f54e7b9ba493b963968358",
            "af2fd06c07a8424dab0ed4fea008cd96",
            "d1b12fdcc67249328461abc04f6ab562",
            "2f0bee2ccc8b44ac9b91d9d4117f357a",
            "5d6c4ddc098c4c8b931e7fa9c0b19eb2",
            "31aa9523b95f4220b72d49328561a6db",
            "6a74872c31b7403dbf8e5660d1e5f2f1"
          ]
        },
        "id": "EiXloyUmLh22",
        "outputId": "f8950fe4-1eac-4079-b438-3c5c44373e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9a8d5b43f68419e9c6991c65b79a906"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b078990051e49f2bff0c0b5f7b57e25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfde8136b3a44dc89ecaec241867f130"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab0b0715063f42ec8d1b6cf167a9d71d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "beb43319ab05419fb6adffeeb3ce9094"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40048b208fa44c2a8538527cd03cf28f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_examples_to_features(example_batch):\n",
        "  input_encodings = tokenizer.batch_encode_plus(example_batch[\"Excerpt\"],\n",
        "                                                pad_to_max_length=True, max_length=200, truncation=True)\n",
        "  target_encodings = tokenizer.batch_encode_plus(example_batch[\"Summary\"],\n",
        "                                                pad_to_max_length=True, max_length=20, truncation=True)\n",
        "  return {\"input_ids\": input_encodings[\"input_ids\"],\n",
        "          \"attention_mask\": input_encodings[\"attention_mask\"],\n",
        "          \"labels\": target_encodings[\"input_ids\"]}\n",
        "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features,\n",
        "                                        batched=True)\n",
        "\n",
        "columns = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
        "dataset_samsum_pt.set_format(type=\"torch\", columns=columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "de9c069bcdc44f5c82f57e3eac9c20a6",
            "36732280bf7d40cf9b1ec4b7f1ba67e7",
            "f82fca4897734508962a87461c89d4b7",
            "0b6003cda2bf42e885db28c317f7cbc9",
            "5780e73ad0124886a87fd2864a754313",
            "a427b33c086947fea460fec12d81ef83",
            "ebf7b629daf74726b3f1d97f688addb5",
            "dafbedfa639a45f1a53ebc326d6d96ad",
            "9a21fc33b49c47b9a79cab0de5187912",
            "0b3ee5f3892b45d08250612d7d18d86e",
            "e74f514603134d098c387622bfa67c87",
            "a295aa2bf6624e83b54ee85b1eaef0c6",
            "184e777532164f06b9a9872ebc33b640",
            "938d2f17c7d641f081f7b961f002703a",
            "cb8f49bdd5e5447ab17a8b4d368426aa",
            "c4400903c9684301ab6a8fc26f03b487",
            "0db333c529264b2bb594fbaf9a57716f",
            "32a9842863ac4b94a1e36d218f7091cd",
            "2077ae1f66854063a61a1ca7c0c3e86b",
            "e0f4bbf7dc9447ccbc9a9e7906181ae7",
            "18bc3a0a9319479b848771e030718b7d",
            "157df8a9304e427ab3d025db0910e222",
            "682edfca6f2448278375770c4887f488",
            "d206b139bed747ea8ed116aa8186ec32",
            "dda16e01646f4c32b4a2d9a66ea70cb7",
            "a0621333be8045d18f229d405dcdb338",
            "9738cc23370541a7ae28b6197629b4dc",
            "1f919268c838478b81e7ad92b9f04359",
            "07a626bf2af5497bb50fce7daa207611",
            "d8a59c1503a54f44b32fc3afd4a1155b",
            "b0e726cabccf4431ae6aff6b27321a54",
            "0dbbcd9904c344a887c25311d3ffa13a",
            "31b1f4666e874428a0a488abf3fc8e4c"
          ]
        },
        "id": "yAqBW9cgHok1",
        "outputId": "cb4640d2-bd7d-4ad8-8359-9d17ebad032d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/49673 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de9c069bcdc44f5c82f57e3eac9c20a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/975 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a295aa2bf6624e83b54ee85b1eaef0c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/96 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "682edfca6f2448278375770c4887f488"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n"
      ],
      "metadata": {
        "id": "Xln2NP-AIQ6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='seo-headline_2', num_train_epochs=6, warmup_steps=500,\n",
        "    per_device_train_batch_size=8, per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01, logging_steps=10,\n",
        "    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n",
        "    gradient_accumulation_steps=16)"
      ],
      "metadata": {
        "id": "qEgH8tTJZIh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide_output\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "01c8f5f0acd24a819a8d75640352d5b7",
            "bed604571b064ecc9b3d58ca18278d0d",
            "d7dc493ba8ed4a29a2e52f465f9a25e2",
            "6e7b555945cf45d591b96ba425c80e0d",
            "d03d778ba7d04217a66b1f0f96ad6467",
            "ccbdb7726cbb428c8b6699d149fd30c8",
            "d99a0eb856724c3b94e8c1e8ca0d4c7b",
            "2da7852f05844e6fb3c4c288806139ca",
            "4ba138ac6dbc4519ad92503107c99ef6",
            "7fb53833226f42079e05fdfde5580855",
            "be52221340fb4758ba25ec4827c6c2ee",
            "e2f8f7faadbb4c25ad8b3acfcd1a756c",
            "05a41d86090648b294943f98d12dc695",
            "5ef232e3e8a543e3bd65eb1a15b9c5a1",
            "2db17a6d65244a3d8531fd9ed5664717",
            "b52adb74c83641969543dc75fd332593",
            "2d55e7e65da64a4990bdf5e8e6b26a47",
            "c83644b46cde4740b996f9103fe0c3e6",
            "a4cbed5370494eacbe769d703b55a7c7",
            "1df10acf7aa544aeb291b2320b22bc96",
            "f448a9498ec04ad2bde7b18f29795e37",
            "52865c7e8c5b46b1a4642ec78b57d43f",
            "b68d492de375425bbacba063ffc07832",
            "7cab5dee6c7646089acae443e34c3ead",
            "7ba9a52dccbc4599b6534bb3a29af4a8",
            "f4dd36c3ba994273af1b3296b8618fe2",
            "705504af1b624bc49cdbb721c8fbaaf0",
            "0469472bf90f4110a3e0644e0782de41",
            "d73df56e02d544228819496da03886ed",
            "0ae0fae6519145e0a70f503db56746b6",
            "90508a45d2ab4350aad53df42e0caef8",
            "001cd1e85b934fcaa79dcb64ed3e06a1"
          ]
        },
        "id": "08o_uyzzZJ1b",
        "outputId": "c3f8cd17-b32b-4924-cff1-95780c5bda08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01c8f5f0acd24a819a8d75640352d5b7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model, args=training_args,\n",
        "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
        "                  train_dataset=dataset_samsum_pt[\"train\"],\n",
        "                  eval_dataset=dataset_samsum_pt[\"valid\"])"
      ],
      "metadata": {
        "id": "viIfISv-ZRAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "Sm0LTUWnZ2Vh",
        "outputId": "fa9af812-f3b3-4343-97bb-1c5ec256f59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2328' max='2328' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2328/2328 2:47:57, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.803100</td>\n",
              "      <td>0.714160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.611700</td>\n",
              "      <td>0.594798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.556800</td>\n",
              "      <td>0.575545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.521900</td>\n",
              "      <td>0.568170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2328, training_loss=1.7527133853165144, metrics={'train_runtime': 10083.3689, 'train_samples_per_second': 29.557, 'train_steps_per_second': 0.231, 'total_flos': 1.681470767087616e+17, 'train_loss': 1.7527133853165144, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "bleu_metric = load_metric(\"sacrebleu\")\n",
        "rouge_metric = load_metric(\"rouge\")\n",
        "\n",
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]"
      ],
      "metadata": {
        "id": "H9M6CjviS-g0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "58e504954420416081c09d64db601613",
            "87a4cb8960664fd98a2ea703237ee48d",
            "3e3df39f2cdf41a8959cb716619ffa6e",
            "e47ee108df72480fa57d21497b26431e",
            "2db12a31ff2946c5916e3d0437dc7206",
            "afd03adfc7824f04a7a20201c1363652",
            "940bc8b4284d411a89ec1d2a42bf8795",
            "4e994b2ed0754f2197e26d30d2139196",
            "5c5bb383765140ea98c81a52aa0d3816",
            "717c7f4189d844928cd344705c670bab",
            "9ecee13f388d4650844b164aadb9a46d",
            "b4d27c3d31e94c82a894f42dd2449739",
            "cf4d135ae307478baa9c37d7885dd6f7",
            "c153395a5be349d98fd3c5d73f343e49",
            "883d7ca410304744808312f9882f5101",
            "9c79457fa81d4e3e8d430a06677947f5",
            "c4c35039f97740aab48c8d71ff0d9f9f",
            "e1647d26d3b443f7a433300141aa9770",
            "bf4328a084ee49c8afbc1cea79dd3d5f",
            "192ea8c685dc447fb72b6b68aac9206a",
            "a592b3bb8fc7434ebf6934baa0592465",
            "73fa4d7aedfb4252abbf7f6fc20c04da"
          ]
        },
        "outputId": "7db262c8-7b42-4916-9897-f3a591f761cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-3e48a45e089f>:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  bleu_metric = load_metric(\"sacrebleu\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/sacrebleu/sacrebleu.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58e504954420416081c09d64db601613"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/rouge/rouge.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4d27c3d31e94c82a894f42dd2449739"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunks(list_of_elements, batch_size):\n",
        "    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
        "    for i in range(0, len(list_of_elements), batch_size):\n",
        "        yield list_of_elements[i : i + batch_size]"
      ],
      "metadata": {
        "id": "Xue5U1wDUiR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n",
        "                               batch_size=16, device=device,\n",
        "                               column_text=\"Excerpt\",\n",
        "                               column_summary=\"Summary\"):\n",
        "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
        "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
        "\n",
        "    for article_batch, target_batch in tqdm(\n",
        "        zip(article_batches, target_batches), total=len(article_batches)):\n",
        "\n",
        "        inputs = tokenizer(article_batch, max_length=200,  truncation=True,\n",
        "                        padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
        "                         attention_mask=inputs[\"attention_mask\"].to(device),\n",
        "                         length_penalty=0.8, num_beams=8, max_length=20)\n",
        "\n",
        "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
        "                                clean_up_tokenization_spaces=True)\n",
        "               for s in summaries]\n",
        "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
        "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
        "\n",
        "    score = metric.compute()\n",
        "    return score"
      ],
      "metadata": {
        "id": "JB7IV3JMUGxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = evaluate_summaries_pegasus(\n",
        "    dataset_samsum[\"test\"], rouge_metric, trainer.model, tokenizer,\n",
        "    batch_size=2, column_text=\"Excerpt\", column_summary=\"Summary\")\n",
        "\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
        "pd.DataFrame(rouge_dict, index=[f\"pegasus\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "c0io8AJ7Qi2Y",
        "outputId": "1fd91842-7575-41ff-ba39-ff05d451217b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/48 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1298: UserWarning: Unfeasible length constraints: `min_length` (32) is larger than the maximum possible length (20). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:23<00:00,  2.07it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           rouge1    rouge2    rougeL  rougeLsum\n",
              "pegasus  0.383108  0.167876  0.355946   0.356255"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2120d74-b2b6-433f-af5a-2d1bff117a8d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pegasus</th>\n",
              "      <td>0.383108</td>\n",
              "      <td>0.167876</td>\n",
              "      <td>0.355946</td>\n",
              "      <td>0.356255</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2120d74-b2b6-433f-af5a-2d1bff117a8d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2120d74-b2b6-433f-af5a-2d1bff117a8d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2120d74-b2b6-433f-af5a-2d1bff117a8d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194,
          "referenced_widgets": [
            "5b30408c3c1144969a69bac3d6874f4b",
            "02cf023a837f4921b98c3f9b87798d74",
            "61f436bed37d4b29b1a27b9c5c86c1c5",
            "c240de7e761a44dea07a0987618895ca",
            "e610c86ba1e941ea9ffdae5786dd7e2a",
            "a92f73944cda414298bef79fd1f46809",
            "8bd277abdf0945b0a6834a2d3106194e",
            "054b243f78a6414e9158ef76afdf5462",
            "127aca243ac841858ab4bc6ead7ec045",
            "875d08b2f8b04ba68dc4325587c23154",
            "20d10d5c66404099b0e90012f1b02b4e",
            "6f25431a091f4214924fe6034e4cc25f",
            "512a2b6427a344c0adecc887445482c1",
            "575c90132d494451adcbb8484b4de833",
            "c1313275408a462095673c4d6ceb810e",
            "7a30066345ea459a8837d00d5669b18b",
            "5e534357629e4b4d9034233f70948786",
            "0bb73d94c85b465199eb1e895c0d0f2e",
            "487e50cc36ac4952a64396ac61ad5ac9",
            "361d90a7856e4d2bbf422c3a2f4742f1",
            "ad7b4652bd444be3b6531f37aad4f08d",
            "4d1fb3d26c6b433391a200c6721e96ac",
            "25875368665b4cf28b67c040f17f071d",
            "dec0330615cc4e698b9556dd21c48f2d",
            "6cae06b7a3fd4fa18de8f60e363c9bf5",
            "9655a08695c641999f74a6e45178c692",
            "477d7dd5d1914398bc97b41eef6c0b5e",
            "8f8808a04430452e918c8734797fa24a",
            "9a23c4848ff14b56a66fc27740f972ef",
            "c34dbdee3490464c84dcf57d4ef737cd",
            "86bb6265aff540f18725a8f0621b5d59",
            "b317189ead044541b848adabb8a9a559",
            "879ddc4252a84cda89f26e12b3ea83f2",
            "59bb77054df14378bb33142e9f37b8af",
            "68cf7db9565345179ae3a8fd6c45813b",
            "da19a64d0eb84043a7cf97408a268373",
            "b0d40e3b241f482387f0450d052e3025",
            "9fd3d0ba4cec4675ab479ad0575c0af3",
            "8b2d19d17c8e41feb39ddefbc0182edd",
            "43d40aec1b704f92ae29f8d342d8af16",
            "f0e651938c7e427785fa3b5247eeb659",
            "6c3aa681f3a749c9b7b5bdc54d4729c4",
            "65b19bf5878b41a9adfcf952b14ee2a3",
            "4175ecdf9e8d4cb198944233ebdf327c",
            "c29936af9ca14311b619626800e0a4e0",
            "460390fe4f7442d0ae4a788d4b0fad21",
            "b15319cd458b43a2845e44f71c63e6c5",
            "08ee33faf1ca4a0298ba608569906eb4",
            "aa73bb8993f94b86b6100f9d38ebbdbf",
            "63ff745a14c94d3c8a3c2fc40c330e12",
            "75c07307c833419cb9271c03ce8b4940",
            "6e782bcc71a64a82b5e268a694dd49ce",
            "a3b04f82992b4b56a9347c1bb3febc01",
            "8203003224c4421cbb2875923e2b3444",
            "d389b4a0df0345ba94b60dd4d69bdfb3"
          ]
        },
        "id": "MAFpO8CDbEK7",
        "outputId": "50c4e747-0cd0-42a4-b847-dabecf3c47ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b30408c3c1144969a69bac3d6874f4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f25431a091f4214924fe6034e4cc25f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "events.out.tfevents.1707228623.adb2d82b8c1a.1198.0:   0%|          | 0.00/42.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25875368665b4cf28b67c040f17f071d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59bb77054df14378bb33142e9f37b8af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "training_args.bin:   0%|          | 0.00/4.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c29936af9ca14311b619626800e0a4e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/abdulmatinomotoso/seo-headline_2/commit/e68caf4877591790341ce188d8668221e68a1a9c', commit_message='Training complete!', commit_description='', oid='e68caf4877591790341ce188d8668221e68a1a9c', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hide\n",
        "import transformers\n",
        "from transformers import pipeline\n",
        "transformers.logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "2CwUe16mWQLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n",
        "sample_text = dataset_samsum[\"test\"][0][\"article\"]\n",
        "reference = dataset_samsum[\"test\"][0][\"headline\"]\n",
        "pipe = pipeline(\"summarization\", model=\"abdulmatinomotoso/pegasus-samsum\")\n",
        "\n",
        "print(\"Dialogue:\")\n",
        "print(sample_text)\n",
        "print(\"\\nReference Summary:\")\n",
        "print(reference)\n",
        "print(\"\\nModel Summary:\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9rso3k-WnO_",
        "outputId": "82c05a05-6110-49dc-cf90-c47a1af7b229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue:\n",
            "Moscow-born Elena Rybakina becameÂ Kazakhstan's first ever winner of Wimbledon today - despite a ban on Russian athletes.The tennis star, 23, who still lives in the Russian capital, has managed to dodge the ban by switching her allegiance and facedÂ Tunisia's OnsÂ Jabeur in Saturday's final on Centre Court.Rybakina rallied from a set down to deny Jabeur her own slice of history with a 3-6 6-2 6-2 victory over the Tunisian world No.2 in Saturday's showdown at the All England Club.The 23-year-old Rybakina is also the youngest women's Wimbledon champion since Petra Kvitova in 2011 after reducing Jabeur to a frustrated wreck during the one-hour, 48-minute title decider.Her semi-final victory had been cheered by Russian-media -Â 'Russian-born star storms into Wimbledon final,' cheered the front page of the Russia Today website.However four years ago Rybakina decided to represent Kazakhstan in tournaments - and she appears to be fed up of questions about Russia.Speaking after her sensational win against World No 1 Halep in the semi-finals, she said:Â 'I'm playing for Kazakhstan for a long time. I'm really happy representing Kazakhstan.'Elena Rybakina, 23, who was born and lives in Moscow, has been able to enter this year's Wimbledon Championships after switching her allegiance to represent Kazakhstan in 2018 Though she was widely regarded as the underdog in the competition, she won in two stunning sets, with the score 4-6, 6-2, 6-2. She was presented with the trophy by Kate MiddletonÂ  Puppy love! The star appears to be a dog lover and has posted photos of herself cuddling pooches on Instagram'They believed in me. There is no more question about how I feel. It's already a long time my journey as a Kazakh player.'Born in Moscow in 1999, Rybakina has been into sports from a young age and used to compete in several different sports with her sister.Her groundstrokes are penetrative and she moves with a grace born of those childhood pursuits.Â The 23-year-old was a gymnast and figure skater as a child but was told she was too tall to have a future in either sport.Â Â  Rybakina (pictured in Dubai) posts photos of herself all around the world as she travels for training and touringElena is private about her personal life but is occasionally spotted out and about at the theatre and visiting other events while not on courtSo she turned her hand to her father's favourite sport, tennis.She first picked up a racquet at the age of six and showed a natural flair for the sport.By the age of 15 she played her first match on the International Tennis Federation circuit in Turkey and turned professional two years later.Rybakina's first ever Grand Slam at the age of 20 saw her crash out in the first round of the French Open. But since then she has only continued to shine. The 23-year-old was a gymnast and figure skater as a child but was told she was too tall to have a future in either sportÂ  British tennis is fined $1m over their ban of Russian athletes, leaving Wimbledon chiefs fumingWimbledon's row with the international tennis authorities over their ban on Russian players has escalated with the British game hit by an extraordinary series of fines totalling $1million.Earlier this month, Sportsmail learned that the WTA has secretly fined the Lawn Tennis Association and the All England Club Â£620,000 and Â£207,000 respectively as a punishment for excluding Russian and Belarusian players from the warm-up tournaments in Eastbourne, Nottingham and Birmingham.The All England Club, who run Wimbledon, and the LTA are set to appeal with the backing of the British Government, who reacted angrily when informed of the fines.'Since February the vast majority of the international sporting community have come together in solidarity to condemn Putin's barbaric actions in Ukraine,' Culture Secretary Nadine Dorries told Sportsmail.'Regrettably the international tennis federations appear determined to be outcasts in this. The LTA and Wimbledon should be praised for their move to make Russia an international sporting pariah, and doing what is right in the current circumstances.'In another worrying development for British tennis there are also concerns about the appeal process. Sportsmail learned that the WTA will only permit an appeal once the fine has been paid in full, leaving the British authorities no option but to shell out over Â£827,000 before they can mount their defence.These concerns are compounded by the fact that the WTA board who will hear the appeal is chaired by WTA chief executive Steve Simon, who was responsible for issuing the original fine.Wimbledon took a unilateral decision to ban the players following high-level talks with the Government who were concerned about handing a propaganda victory to Vladimir Putin's regime.It caused a major split in the tennis world with the ATP and WTA - the men's and women's tours - retaliating by removing ranking points from this year's Championships.Â Â Off-court Rybakina is fairly private, but she shares snippets of her personal life and behind-the-scenes on tour.Seemingly a dog lover, the 23-year-old visited a dog shelter in November last year to meet some of the pooches up for adoption.The rising star also posts photos of herself posing near world landmarks, such as the London Eye and the Eiffel Tower, in places she gets to visit on tour.Despite being a private and low-key player, she has been court up in controversy during this year's competition.Â Following Russia's invasion of Ukraine in February Russian tennis players were banned from entering this year's Wimbledon Championships.But having represented Kazakhstan since 2018, the 23-year-old is proud of her heritage.In an Instagram post last September Rybakina smiled while holding up the flag of Kazakhstan.Â She wrote: 'For the first time the WTA 250 tournament will take place in Kazakhstan in a couple of weeks!Â 'I am very happy about this event and would like to say a big thank you [to theÂ Kazakhstan Tennis Federation].'She added hosting the tournament was a great opportunity for the 'development of tennis in the country'.Â Â Responding to questions at a press conference on Thursday the World No. 23 would not reveal how much time she spends in Moscow.However she said she primarily trains for tournaments in Slovakia and Dubai.Â 'I don't live anywhere, to be honest,' she said.Â Since then, she has tried to navigate difficult questions over whether she sees herself as Russian - of as Kazakh.Â Ahead of the final, she said: 'It's a tough question to say what I feel.'I was born in Russia, but I am really happy that I'm representing Kazakhstan. They were looking for a player and I was looking for help.Â 'I'm feeling the support of the people because I'm bringing results which are very good for the sport in Kazakhstan.'Rybakina did admit she felt sorry for the Russians who were barred from competing at Wimbledon.Â But when pressed on her thoughts on the country's invasion of Ukraine, she said: 'I just want the war to end as soon as possible.'She is also Kazakhstan's first ever finalist in a Grand Slam tournament.But the Moscow-born star's triumph was not without controversy as tennis great John McEnroe called her participation into question following the All England Club's ban on Russian and Belarusian players because of Vladamir Putin's war on Ukraine.'She is obviously a huge hitter and hits the ball great,' McEnroe said from the BBC commentary booth.Kazakhstan's Elena celebrates with the trophy after winning the women's singles final against Tunisia's Ons Jabeur Kate presented the Venus Rosewater Dish on Centre Court this afternoon to Elena, exchanging a few words with the playerÂ  The Duchess went on to present Elana with the trophy after the riveting match on Centre Court this afternoonÂ 'I just think it's weird because of this whole thing. I don't mean to get into politics here but she is Russian, right?'It is sort of strange because of this whole ordeal of not allowing the Russians to play.'While Russian men's world No.1 Daniil Medvedev was among those unable to compete, Rybakina marched through the women's title for the concession of just two sets.Rybakina also dropped the opening set in her quarter-final against Australian Ajla Tomljanovic.But the 17th seed otherwise flattened her vanquished opponents - including grand slam champions Bianca Andreescu and 2019 Wimbledon winner Simona Halep - with her deadly serve and fearless back-court power game.Jabeur had been bidding to become first African woman to win Wimbledon and first Arab to claim a grand slam singles title in the 55-year Open era.But the 27-year-old was ultimately left to rue being only able to convert two of 11 break-point chances, looking hot and bothered in London's SW19.\n",
            "\n",
            "Reference Summary:\n",
            "Wimbledon: Moscow-born Elena Rybakina becomes first Kazakhstaner to win the women's title after switch to team up with country's tennis stars\n",
            "\n",
            "Model Summary:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "Xuf2i2ekfm_U",
        "outputId": "bca4c162-a034-454a-9c0c-d1779ec31b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-986d8602cce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"summary_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m               \u001b[0mids\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \"\"\"\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \"\"\"\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         if (\n\u001b[1;32m    139\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    957\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"min_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;31m# and added to `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0;32m-> 1182\u001b[0;31m                 \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             )\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0membed_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0membed_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids_shape, past_key_values_length)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_values_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         )\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2181\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_dialogue = \"\"\"\\\n",
        "The NAACP is calling on the Boston School Committee not to choose a new superintendent Wednesday, calling the search process â€œfundamentally flawedâ€ from its short timeline to the lack of Black and Latino finalists.â€œThe lack of representation in the finalist pool should have immediately caused the process to pause, review, and reopen (if necessary),â€ Tanisha Sullivan, the organizationâ€™s president, wrote in a letter that was sent to School Committee Chair Jeri Robinson Friday.A search committee, jointly appointed by Mayor Michelle Wu and the School Committee, had hoped to present a more diverse slate of finalists, but two would be-finalists, a Latina and a Black woman, withdrew prior to the announcement. The remaining two are Somerville Superintendent Mary Skipper, who is white, and Tommy Welch, who is Japanese American and white.They are competing to replace outgoing Superintendent Brenda Cassellius who is leaving Thursday.Meanwhile, competition for Skipper intensified Monday night. The School Committee authorized its chair to sign a two-year extension to Skipperâ€™s contract, which expires Thursday. The agreement, however, still allows for Skipper to go to Boston with at least 90 days notice.Having no Black or Latino finalists is a departure from past superintendent searches in a district where about three-quarters of students identify that way. A number of education advocates, including City Councilor Julia Mejia, have expressed disappointment over the lack of Black and Latino finalists.Sullivan in her letter urged the School Committee to expand the slate of finalists so thereâ€™s a more robust mix of representation and experience, noting that having only â€œtwo finalists for a nationally respected district like Boston should raise an automatic caution flag in the process.â€The search also was done at an unusually fast pace, Sullivan said. The job was posted in April and finalists were chosen two months later. Previous searches spent many months between those two critical bookends recruiting and vetting candidates.Other organizations, including Democrats for Education Reform and Bostonians for an Elected School Committee, also have raised concerns about the short timeline and wonder if a longer search would have yielded a more robust final slate.Robinson immediately rejected the NAACPâ€™s request to expand the pool of finalists, according to a letter she sent Friday to Sullivan, which was shared with the Globe, noting â€œour kids cannot wait any longer, and we cannot let this opportunity pass us by.â€â€œWhile I share your disappointment that our search did not result in a more racially diverse group of public interviews, I stand by this process. I am confident both candidates have the necessary qualifications and are uniquely positioned to lead our District forward,â€ Robinson wrote.Sullivan, who is running for secretary of state, also questions whether the search could have yielded a larger pool of finalists if it waited until after Wu and state Education Commissioner Jeffrey Riley finished negotiating a district-improvement plan, which was completed Monday.Sullivan stressed that she thinks highly of both finalists and noted both are qualified to be superintendent, but added the public deserves to have a more robust slate. Wu told the Globe last week looming concerns about a possible state takeover of Boston Public Schools weighed on potential candidates.Sullivan reiterated her concerns in an interview Tuesday with the Globe.â€œI do think the process itself yielded the results we have because the district underestimated the impact that the state level issues would have on otherwise interested candidates being willing to move forward,â€ Sullivan said. â€œTo me having this agreement signed by the interested parties now helps to set fully both what the educational and political landscapes will be for anyone coming into the district.â€The Globeâ€™s Great Divide team explores educational inequality in Boston and statewide. Sign up to receive our newsletter, and send ideas and tips to thegreatdivide@globe.com.James Vaznis can be reached at james.vaznis@globe.com. Follow him on Twitter @globevaznis.\",\n",
        "\"\"\"\n",
        "print(pipe(custom_dialogue, **gen_kwargs)[0][\"summary_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxD2ipqLW-9I",
        "outputId": "9295400b-43c8-412e-cda3-99d5f5673653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The NAACP is calling on the Boston School Committee not to choose a new superintendent Wednesday .<n>A search committee had hoped to present a more diverse slate of finalists, but two would be-finalists, a Latina and a Black woman, withdrew prior to the announcement .<n>The remaining two are Somerville Superintendent Mary Skipper, who is white, and Tommy Welch, who is Japanese American and white .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G9wKlexbYNzy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}